<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Process Reward Model (PRM)  | Alive-mk</title>
<link rel="shortcut icon" href="https://Alive-mk.github.io/favicon.ico?v=1770951170092">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://Alive-mk.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Process Reward Model (PRM)  | Alive-mk - Atom Feed" href="https://Alive-mk.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="1. 核心概念与论文溯源 (Concept &amp; Paper Roots)
论文引用

核心论文：&quot;Let's Verify Step by Step&quot; (OpenAI, 2023)
作者：Hunter Light..." />
    <meta name="keywords" content="实习" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://Alive-mk.github.io">
  <img class="avatar" src="https://Alive-mk.github.io/images/avatar.png?v=1770951170092" alt="">
  </a>
  <h1 class="site-title">
    Alive-mk
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Process Reward Model (PRM) 
            </h2>
            <div class="post-info">
              <span>
                2026-02-08
              </span>
              <span>
                30 min read
              </span>
              
                <a href="https://Alive-mk.github.io/tag/pt1Ejsp1Pa/" class="post-tag">
                  # 实习
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <h3 id="1-核心概念与论文溯源-concept-paper-roots">1. 核心概念与论文溯源 (Concept &amp; Paper Roots)</h3>
<h4 id="论文引用"><strong>论文引用</strong></h4>
<ul>
<li><strong>核心论文</strong>：<strong>&quot;Let's Verify Step by Step&quot;</strong> (OpenAI, 2023)</li>
<li><strong>作者</strong>：Hunter Lightman, Vineet Kosaraju, et al.</li>
<li><strong>链接</strong>：</li>
<li><em>关联阅读</em>：DeepMind 的 <em>&quot;Solving Math Word Problems with Process- and Outcome-Based Feedback&quot;</em> (2022) 也是必须了解的前序工作。</li>
</ul>
<h4 id="本质概括"><strong>本质概括</strong></h4>
<p><strong>“细粒度的信用分配（Fine-grained Credit Assignment）”</strong>。</p>
<p>从数学直觉上讲，它将一个稀疏的、高方差的<strong>结果信号</strong>（Final Answer Correctness），分解为密集的、低方差的<strong>步骤信号</strong>（Step-wise Correctness）。</p>
<h4 id="痛点解决"><strong>痛点解决</strong></h4>
<p>在 PRM 出现之前，主流是 <strong>ORM (Outcome Reward Model)</strong>，即只看最终答案对不对。ORM 存在两个巨大痛点：</p>
<ol>
<li><strong>虚假相关性（Spurious Correlation）</strong>：模型可能推理过程全错，但运气好撞对了答案（False Positive）。ORM 会奖励这种错误逻辑。</li>
<li><strong>稀疏反馈（Sparse Reward）</strong>：在长链条推理（如奥数题或长代码）中，如果最后一步错了，ORM 会惩罚整个链条，导致模型不知道具体哪一步错了，训练效率极低。</li>
</ol>
<p><strong>PRM 的解决之道</strong>：通过人工标注或自动构造数据，对推理过程中的<strong>每一步</strong>（Step）进行打分。这让模型能精确知道“走到哪一步开始偏离了真理”。</p>
<hr>
<h3 id="2-数学原理与推导-mathematical-underpinning">2. 数学原理与推导 (Mathematical Underpinning)</h3>
<h4 id="核心定义与对比"><strong>核心定义与对比</strong></h4>
<p>假设一个推理问题 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>，模型生成了一个思维链 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span>，该思维链包含 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 个步骤：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mo>(</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mi>K</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\hat{y} = (s_1, s_2, ..., s_K)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</p>
<p><strong>1. 结果监督 (Outcome Supervision, ORM):</strong></p>
<p>通常只在最后时刻 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 给出一个奖励 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>∈</mo><mo>{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>}</mo></mrow><annotation encoding="application/x-tex">r \in \{0, 1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span>。</p>
<p>目标是最大化生成正确答案的期望奖励。损失函数通常针对整个序列：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>J</mi><mrow><mi>O</mi><mi>R</mi><mi>M</mi></mrow></msub><mo>(</mo><mi>θ</mi><mo>)</mo><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub></mrow></msub><mo>[</mo><mi>r</mi><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>)</mo><mo>⋅</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">J_{ORM}(\theta) = - \mathbb{E}_{\hat{y} \sim \pi_\theta} [r(\hat{y}) \cdot \log \pi_\theta(\hat{y}|x)]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord">−</span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>或者在训练 Reward Model 时，将整条路径作为样本 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo separator="true">,</mo><mi>r</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(x, \hat{y}, r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> 进行二分类或回归。</p>
<blockquote>
<p>这是一个非常经典且基础的强化学习（RL）与大模型对齐（Alignment）的概念。针对您提供的 <strong>Outcome Supervision (ORM)</strong> 定义和公式，我将分两个层次为您解读。</p>
<hr>
<h3 id="第一部分深度学术解析-academic-deep-dive">第一部分：深度学术解析 (Academic Deep Dive)</h3>
<p>在学术界和工业界算法岗的语境下，ORM 代表了一种<strong>稀疏的、粗粒度的（Coarse-grained）反馈机制</strong>。</p>
<h4 id="1-数学本质策略梯度与期望最大化">1. 数学本质：策略梯度与期望最大化</h4>
<p>公式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>J</mi><mrow><mi>O</mi><mi>R</mi><mi>M</mi></mrow></msub><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J_{ORM}(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 本质上是 <strong>Policy Gradient (策略梯度)</strong> 的变体。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>J</mi><mrow><mi>O</mi><mi>R</mi><mi>M</mi></mrow></msub><mo>(</mo><mi>θ</mi><mo>)</mo><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub></mrow></msub><mo>[</mo><mi>r</mi><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>)</mo><mo>⋅</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">J_{ORM}(\theta) = - \mathbb{E}_{\hat{y} \sim \pi_\theta} [r(\hat{y}) \cdot \log \pi_\theta(\hat{y}|x)]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord">−</span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<ul>
<li>
<p><strong>符号拆解</strong>：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\pi_\theta(\hat{y}|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>：当前的策略网络（即 LLM），给定输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 生成完整序列 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span> 的概率。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>)</mo></mrow><annotation encoding="application/x-tex">r(\hat{y})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：<strong>标量奖励（Scalar Reward）</strong>。在 ORM 中，这个值仅在序列结束（EOS）时计算一次。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mi mathvariant="double-struck">E</mi></mrow><annotation encoding="application/x-tex">-\mathbb{E}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77222em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathbb">E</span></span></span></span></span>：因为通常优化器是做“梯度下降”（Minimize Loss），而我们要“最大化奖励”，所以加负号。</li>
</ul>
</li>
<li>
<p><strong>梯度的物理意义</strong>：</p>
<p>对该损失函数求导，得到的梯度方向是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mo>≈</mo><mo>−</mo><mi>r</mi><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>)</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\nabla_\theta J \approx - r(\hat{y}) \nabla_\theta \log \pi_\theta(\hat{y}|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>。</p>
<p>这意味着：<strong>如果通过蒙特卡洛采样（Monte Carlo Sampling）得到的一条路径 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span> 获得了高分 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>，我们就推高生成该路径上所有 Token 的对数概率；反之则抑制。</strong></p>
</li>
</ul>
<h4 id="2-orm-的两种训练范式">2. ORM 的两种训练范式</h4>
<p>文案中提到的“二分类或回归”是指 <strong>Reward Model (RM)</strong> 本身的训练，而非 Policy 的训练。</p>
<ul>
<li><strong>Pointwise Regression/Classification</strong>：直接将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>)</mo></mrow><annotation encoding="application/x-tex">(x, \hat{y})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 映射到一个分数。比如训练一个 BERT 或 GPT 判断答案是对是错（Binary Cross Entropy）。</li>
<li><strong>Pairwise Ranking (Bradley-Terry Model)</strong>：目前更主流的做法（如 RLHF 中的 PPO）。不直接预测绝对分数，而是预测 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>w</mi></msub><mo>≻</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_w \succ \hat{y}_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≻</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（胜者优于败者）的概率。</li>
</ul>
<h4 id="3-核心缺陷时间信用分配问题-temporal-credit-assignment">3. 核心缺陷：时间信用分配问题 (Temporal Credit Assignment)</h4>
<p>ORM 最大的学术痛点在于 <strong>Credit Assignment（信用分配）</strong> 的失效。</p>
<ul>
<li><strong>现象</strong>：假设模型生成了 100 个 Token 的推理步骤。其中第 50 步出现了一个致命逻辑错误，但第 90 步运气好猜对了答案，导致 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">r=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>。</li>
<li><strong>后果</strong>：根据公式，ORM 会无差别地奖励整条路径中的每一个 Token。这意味着<strong>错误的第 50 步也被“强化”了</strong>。这种噪声会导致模型训练收敛慢，甚至学会“投机取巧”（Spurious Correlations）。</li>
</ul>
<hr>
<h3 id="第二部分通俗易懂的解释-layman-explanation">第二部分：通俗易懂的解释 (Layman Explanation)</h3>
<p>如果把训练 AI 比作教学生做数学题，那么 <strong>结果监督 (ORM)</strong> 就是一位**“只看结果，不看过程”的严厉老师**。</p>
<h4 id="1-场景类比只看答案的考试">1. 场景类比：只看答案的考试</h4>
<p>想象你正在参加一场奥数考试：</p>
<ul>
<li><strong>题目 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>)</strong>：求解一个复杂的几何题。</li>
<li><strong>你的回答 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span>)</strong>：写了 20 行的推导过程，最后得出答案“面积是 50”。</li>
<li><strong>ORM 老师的打分 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>)</strong>：老师根本不看你那 20 行推导写了什么。他只看最后一行数字。
<ul>
<li>如果答案是 50 -&gt; <strong>满分 (Reward = 1)</strong>。</li>
<li>如果答案是 49 -&gt; <strong>零分 (Reward = 0)</strong>。</li>
</ul>
</li>
</ul>
<h4 id="2-那个复杂的公式在说什么">2. 那个复杂的公式在说什么？</h4>
<p>公式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>)</mo><mo>⋅</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">r(\hat{y}) \cdot \log \pi_\theta(\hat{y}|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span> 翻译成白话就是：</p>
<blockquote>
<p><strong>“这次蒙对了，那就把刚刚说过的每一句话都当成‘真理’记在脑子里；如果蒙错了，就认为刚刚说的每一句话都是‘废话’，以后少说。”</strong></p>
</blockquote>
<h4 id="3-这种方法的问题为什么我们需要-prm">3. 这种方法的问题（为什么我们需要 PRM？）</h4>
<p>这就好比你做题时，第 3 步公式用错了，但最后阴差阳错算对了答案。</p>
<ul>
<li><strong>ORM 老师说</strong>：“干得漂亮！你第 3 步那个错误的公式用得真好，下次继续用！”</li>
<li><strong>后果</strong>：你（AI）会因此学到错误的知识，变得只会“蒙答案”，而不是真正学会了推理。</li>
</ul>
<p><strong>总结</strong>：ORM 是“不管黑猫白猫，抓到老鼠就是好猫”；而 PRM（过程监督）则是“不仅要抓到老鼠，还要步法矫健、姿势正确”。</p>
</blockquote>
<p><strong>2. 过程监督 (Process Supervision, PRM):</strong></p>
<p>我们在每一步 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">s_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 都有一个标签 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>l</mi><mi>k</mi></msub><mo>∈</mo><mo>{</mo><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo>}</mo></mrow><annotation encoding="application/x-tex">l_k \in \{+1, -1, 0\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">+</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mclose">}</span></span></span></span>（正确、错误、中立）。PRM 的目标是预测每一步的正确性。</p>
<p>通常建模为一个<strong>Token级别的分类任务</strong>。假设 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>t</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>e</mi><mi>n</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{k, end}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 步结束时的 Token 索引。</p>
<p>PRM 的损失函数通常是每一步的 Cross-Entropy Loss 之和：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>P</mi><mi>R</mi><mi>M</mi></mrow></msub><mo>(</mo><mi>ϕ</mi><mo>)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>log</mi><mo>⁡</mo><msub><mi>P</mi><mi>ϕ</mi></msub><mo>(</mo><msub><mi>l</mi><mi>k</mi></msub><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{PRM}(\phi) = - \sum_{k=1}^{K} \log P_\phi(l_k \mid x, s_1, ..., s_k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">ϕ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1304490000000005em;vertical-align:-1.302113em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<blockquote>
<p>这一部分是 <strong>Process Reward Model (PRM)</strong> 的核心定义，它代表了从“面向结果”到“面向过程”的范式转变。</p>
<hr>
<h3 id="第一部分深度学术解析-academic-deep-dive-2">第一部分：深度学术解析 (Academic Deep Dive)</h3>
<p>在学术界，<strong>过程监督 (PRM)</strong> 本质上是将一个长视距（Long-horizon）的推理问题，分解为一系列短视距（Short-horizon）的判别问题。这解决了强化学习中的**稀疏奖励（Sparse Reward）**难点。</p>
<h4 id="1-建模token-级别的判别任务-discriminative-task">1. 建模：Token 级别的判别任务 (Discriminative Task)</h4>
<p>公式中的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span> 代表 PRM 的参数（通常是基于 LLM 的 Encoder 或 Decoder 加上一个分类头）。</p>
<ul>
<li>
<p><strong>输入空间</strong>：输入不仅是当前步骤 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">s_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，而是完整的上下文 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mi>k</mi></msub><mo>=</mo><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">H_k = (x, s_1, ..., s_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。这意味着模型必须理解之前的逻辑流。</p>
</li>
<li>
<p><strong>分类头 (Classification Head)</strong>：</p>
<p>与生成模型预测下一个 Token 不同，PRM 在特定位置 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>t</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>e</mi><mi>n</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{k, end}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>（即第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 步的结束符，如 <code>\n</code> 或 <code>&lt;EOS&gt;</code>）提取 Hidden State <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><msub><mi>t</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>e</mi><mi>n</mi><mi>d</mi></mrow></msub></msub></mrow><annotation encoding="application/x-tex">h_{t_{k, end}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04752em;vertical-align:-0.35307999999999995em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35307999999999995em;"><span></span></span></span></span></span></span></span></span></span>。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><msub><mi>t</mi><mi>k</mi></msub><mo>=</mo><mtext>Linear</mtext><mo>(</mo><msub><mi>h</mi><msub><mi>t</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>e</mi><mi>n</mi><mi>d</mi></mrow></msub></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">logit_k = \text{Linear}(h_{t_{k, end}})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">i</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1030799999999998em;vertical-align:-0.35307999999999995em;"></span><span class="mord text"><span class="mord">Linear</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35307999999999995em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>ϕ</mi></msub><mo>(</mo><msub><mi>l</mi><mi>k</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>H</mi><mi>k</mi></msub><mo>)</mo><mo>=</mo><mtext>Softmax</mtext><mo>(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><msub><mi>t</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">P_\phi(l_k | H_k) = \text{Softmax}(logit_k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">i</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>这是一个标准的判别式建模。</p>
<blockquote>
<p>这是一个非常经典的机器学习面试题，也是理解大模型（LLM）如何从“生成”转向“判别”的关键。</p>
<h3 id="1-核心定义什么是判别式建模">1. 核心定义：什么是判别式建模？</h3>
<p><strong>判别式建模 (Discriminative Modeling)</strong> 的核心数学本质是建模<strong>条件概率分布 (Conditional Probability Distribution)</strong>：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>Y</mi><mo>∣</mo><mi>X</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">P(Y \mid X)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span> (Observation/Input)</strong>：观测数据或特征。在这里，就是模型的 Hidden State (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><msub><mi>t</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>e</mi><mi>n</mi><mi>d</mi></mrow></msub></msub></mrow><annotation encoding="application/x-tex">h_{t_{k, end}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04752em;vertical-align:-0.35307999999999995em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35307999999999995em;"><span></span></span></span></span></span></span></span></span></span>) 代表的上下文信息。</li>
<li><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span> (Target/Label)</strong>：我们要预测的目标。在这里，就是步骤的正确性标签 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>l</mi><mi>k</mi></msub><mo>∈</mo><mo>{</mo><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo>}</mo></mrow><annotation encoding="application/x-tex">l_k \in \{+1, -1, 0\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">+</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mclose">}</span></span></span></span>。</li>
</ul>
<p><strong>一句话概括</strong>：判别式模型不关心 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span> 是怎么生成的，它只关心<strong>给定 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span> 的情况下，它是类别 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span> 的概率是多少</strong>。它的任务是划定一个<strong>决策边界 (Decision Boundary)</strong>。</p>
<hr>
<h3 id="2-结合你的公式深度解析">2. 结合你的公式深度解析</h3>
<p>让我们回到你提供的公式，看看它是如何体现“判别式”特性的：</p>
<ol>
<li><strong>特征提取 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>)</strong>:
<ul>
<li>输入是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><msub><mi>t</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>e</mi><mi>n</mi><mi>d</mi></mrow></msub></msub></mrow><annotation encoding="application/x-tex">h_{t_{k, end}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04752em;vertical-align:-0.35307999999999995em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35307999999999995em;"><span></span></span></span></span></span></span></span></span></span>。这是 Base Model (Transformer) 经过深层计算后压缩出的高维向量。</li>
<li>在判别式任务中，这被称为 <strong>Feature Extraction</strong>。Base Model 充当了特征提取器。</li>
</ul>
</li>
<li><strong>决策边界映射 (Mapping)</strong>:
<ul>
<li><code>logit_k = Linear(...)</code>：这是一个线性变换 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>⋅</mo><mi>h</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">W \cdot h + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span>。</li>
<li><strong>几何意义</strong>：这相当于在高维特征空间中切了一刀（或者几刀）。它试图找到一个超平面，把“正确的步骤”和“错误的步骤”在空间上分开。</li>
</ul>
</li>
<li><strong>概率输出 (Probability)</strong>:
<ul>
<li><code>Softmax(...)</code>：将距离超平面的距离（Logits）转化为归一化的概率。</li>
<li><strong>结果</strong>：直接输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mtext>Correct</mtext><mo>∣</mo><mtext>Context</mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">P(\text{Correct} \mid \text{Context})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">Correct</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Context</span></span><span class="mclose">)</span></span></span></span>。</li>
</ul>
</li>
</ol>
<p><strong>结论</strong>：这就是最标准的<strong>分类器 (Classifier)</strong> 架构，属于判别式建模的典型代表（Logistic Regression 就是最简单的判别式模型）。</p>
<hr>
<h3 id="3-面试必考判别式-vs-生成式-discriminative-vs-generative">3. 面试必考：判别式 vs. 生成式 (Discriminative vs. Generative)</h3>
<p>在算法面试中，讲判别式必须对比生成式，这是<strong>T5/P6 级别的必考题</strong>。</p>
<h4 id="结合-prm-场景的深度理解">结合 PRM 场景的深度理解：</h4>
<ul>
<li><strong>GPT (Base Model) 是生成式的</strong>：它在计算 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">P(x_t \mid x_{&lt;t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，它的目的是通过概率采样<strong>创造</strong>下一个 Token。</li>
<li><strong>PRM (Reward Head) 是判别式的</strong>：它不创造任何新 Token。它只是站在“评论家”的角度，看着 GPT 生成的内容 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>)，给出“对”或“错”的判断 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>)。</li>
</ul>
<h3 id="4-为什么-prm-要用判别式">4. 为什么 PRM 要用判别式？</h3>
<p>在面试中，如果被问到“为什么不直接让 LLM 生成‘这个步骤是对的’这句话？”，你可以这样回答：</p>
<ol>
<li><strong>信号密度与精度</strong>：判别式建模（分类头）直接作用于高维向量，梯度回传更直接、更纯粹。让 LLM 生成文本（&quot;Yes/No&quot;）引入了额外的解码噪声。</li>
<li><strong>计算效率</strong>：<code>Linear + Softmax</code> 的计算量相对于整个 Decoder 生成过程几乎可以忽略不计。</li>
<li><strong>任务本质</strong>：验证（Verification）本质上就是一个<strong>分类问题</strong>（Binary/Multi-class Classification），用判别式建模是数学上最匹配的范式。</li>
</ol>
<p><strong>总结</strong>：在你的公式里，Transformer 负责“理解”（提取特征），Linear+Softmax 负责“判决”（判别式分类）。这就是 PRM 的工作流。</p>
</blockquote>
</li>
</ul>
<h4 id="2-损失函数解析最大似然估计-mle">2. 损失函数解析：最大似然估计 (MLE)</h4>
<p>公式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>P</mi><mi>R</mi><mi>M</mi></mrow></msub><mo>(</mo><mi>ϕ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{PRM}(\phi)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">ϕ</span><span class="mclose">)</span></span></span></span> 是标准的<strong>交叉熵损失（Cross-Entropy Loss）</strong>。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>P</mi><mi>R</mi><mi>M</mi></mrow></msub><mo>(</mo><mi>ϕ</mi><mo>)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>log</mi><mo>⁡</mo><msub><mi>P</mi><mi>ϕ</mi></msub><mo>(</mo><msub><mi>l</mi><mi>k</mi></msub><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mi>k</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{PRM}(\phi) = - \sum_{k=1}^{K} \log P_\phi(l_k \mid x, s_1, ..., s_k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">ϕ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1304490000000005em;vertical-align:-1.302113em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li><strong>独立性假设的修正</strong>：虽然公式写成求和形式，看似每一步独立，但由于输入包含了 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>s</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">s_1...s_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，每一步的评估实际上是<strong>条件独立</strong>的（Conditionally Independent）。</li>
<li><strong>标签含义 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>l</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">l_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></strong>：
<ul>
<li><strong>Positive (+1)</strong>：该步骤逻辑正确，且对解决问题有贡献。</li>
<li><strong>Negative (-1)</strong>：该步骤存在逻辑错误、计算错误或幻觉。</li>
<li><strong>Neutral (0)</strong>：该步骤是正确的，但没有实质性推进（例如复述题目），或者存在歧义。在 OpenAI 的 <em>Let's Verify Step by Step</em> 中，Neutral 的处理非常关键，通常不给予高奖励也不惩罚，但在某些变体中会被视为“软错误”。</li>
</ul>
</li>
</ul>
<h4 id="3-为什么是密集信号-dense-signal">3. 为什么是“密集信号” (Dense Signal)？</h4>
<p>相比于 ORM 的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>J</mi><mrow><mi>O</mi><mi>R</mi><mi>M</mi></mrow></msub></mrow><annotation encoding="application/x-tex">J_{ORM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 只在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 时刻有梯度回传，PRM 在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">k=1, ..., K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 的每一个时刻都有梯度回传。</p>
<p>从优化角度看，这极大地降低了梯度的<strong>方差（Variance）</strong>。</p>
<ul>
<li><strong>ORM</strong>：整条路走完才知道错了，梯度更新是“模糊”的。</li>
<li><strong>PRM</strong>：走错第一步时，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>P</mi><mi>R</mi><mi>M</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}_{PRM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 处就会产生巨大的 Loss，立即修正模型参数，防止错误累积（Error Accumulation）。</li>
</ul>
<hr>
<h3 id="第二部分通俗易懂的解释-layman-explanation-2">第二部分：通俗易懂的解释 (Layman Explanation)</h3>
<p>如果说 ORM 是只看分数的“严厉老师”，那么 <strong>过程监督 (PRM)</strong> 就是一位**“手把手教做题”的耐心私教**。</p>
<h4 id="1-场景类比gps-导航">1. 场景类比：GPS 导航</h4>
<p>想象你要开车从北京去上海（完成一个复杂的推理任务）：</p>
<ul>
<li><strong>ORM (结果监督)</strong>：你闷头一直开，开到了广州（终点错了）。这时候导航才告诉你：“你到了错误的城市，任务失败。”它没告诉你哪里开错了，你只能下次重新瞎蒙。</li>
<li><strong>PRM (过程监督)</strong>：
<ul>
<li>你刚开出北京五环，往西转了。</li>
<li><strong>导航（PRM）立马提示</strong>：“这一步错了（标签 -1）！应该往南走。”</li>
<li>你修正方向，继续开。</li>
<li>开到济南，你停下来加了个油。</li>
<li><strong>导航（PRM）提示</strong>：“这一步没问题，但对赶路没直接帮助，中立（标签 0）。”</li>
<li>你上了京沪高速。</li>
<li><strong>导航（PRM）提示</strong>：“这一步很棒，方向正确（标签 +1）！”</li>
</ul>
</li>
</ul>
<h4 id="2-prm-到底在算什么">2. PRM 到底在算什么？</h4>
<p>那个求和的公式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∑</mo></mrow><annotation encoding="application/x-tex">\sum</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span></span></span></span> 翻译成白话就是：</p>
<blockquote>
<p><strong>“我要盯着你走的每一步。如果你这一步走对了，我就给你积一分；如果这一步走错了，我就扣一分。我要让你在解题的任何一个环节，都知道自己现在的状态是好是坏，而不是等到最后交卷了才后悔。”</strong></p>
</blockquote>
<h4 id="3-核心价值">3. 核心价值</h4>
<p>通过这种方式，AI 不再需要“背答案”，而是学会了**“每走一步都回头确认一下”**的严谨逻辑。这就是为什么 OpenAI 的 o1 模型在数学题上那么强——它学会了自我检查。</p>
</blockquote>
<h4 id="论文中的数学视角与-trick"><strong>论文中的数学视角与 Trick</strong></h4>
<ul>
<li>
<p><strong>Active Learning（主动学习）</strong>：OpenAI 在论文中强调，PRM 的标注成本很高。他们使用了一个关键 Trick：<strong>仅标注模型确信度高但实际上错误的步骤（Hard Negatives）</strong>。</p>
</li>
<li>
<p><strong>评分映射</strong>：在推理（Inference）阶段，PRM 对第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 步给出的分数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>=</mo><mi>P</mi><mo>(</mo><msub><mi>l</mi><mi>k</mi></msub><mo>=</mo><mtext>positive</mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">v_k = P(l_k = \text{positive})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">positive</span></span><span class="mclose">)</span></span></span></span>。整个路径的得分通常定义为所有步骤得分的乘积（概率连乘）或最小值（短板效应）：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mtext>Score</mtext><mrow><mi>p</mi><mi>a</mi><mi>t</mi><mi>h</mi></mrow></msub><mo>=</mo><munderover><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>v</mi><mi>k</mi></msub><mspace width="1em"/><mtext>or</mtext><mspace width="1em"/><munder><mi>min</mi><mo>⁡</mo><mi>k</mi></munder><msub><mi>v</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\text{Score}_{path} = \prod_{k=1}^K v_k \quad \text{or} \quad \min_{k} v_k
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord text"><span class="mord">Score</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1304490000000005em;vertical-align:-1.302113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:1em;"></span><span class="mord text"><span class="mord">or</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:1em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7521079999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>OpenAI 的论文发现，在 Best-of-N 搜索中，<strong>乘积（Product）</strong> 或者是对数和（Sum of Logs）通常比最小值效果更好，因为它代表了“全对的联合概率”。</p>
</li>
</ul>
<blockquote>
<h3 id="第一部分深度学术解析-academic-deep-dive-3">第一部分：深度学术解析 (Academic Deep Dive)</h3>
<h4 id="1-active-learning-hard-negatives-主动学习与难负样本挖掘">1. Active Learning &amp; Hard Negatives (主动学习与难负样本挖掘)</h4>
<p><strong>学术背景：</strong></p>
<p>在训练 PRM 时，如果随机采样模型生成的推理步骤进行人工标注，你会发现绝大多数样本是“微不足道”的（Trivial）。例如，简单的算术步骤模型几乎总是对的，标注这些样本对模型参数更新的贡献（Gradient Magnitude）极小。</p>
<p><strong>Hard Negatives (难负样本) 的定义：</strong></p>
<p>OpenAI 定义的 Hard Negative 是指那些 <strong>生成的答案错误（Outcome is Incorrect），但模型对其中某一步骤给出了高置信度（High Confidence）</strong> 的样本。</p>
<ul>
<li><strong>数学直觉</strong>：这对应于分类面（Decision Boundary）附近的样本。在 SVM 或 Boosting 算法中，这些就是“支持向量”或权重最高的样本。</li>
<li><strong>Active Learning 循环</strong>：
<ol>
<li>训练一个当前的 PRM <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\theta_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li>使用 Generator 生成大量思维链 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span>。</li>
<li>筛选出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span> 中最终答案错误，但 PRM <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\theta_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 却给每一步都打高分的路径。</li>
<li><strong>只人工标注这些路径中的第一个错误步骤。</strong></li>
<li>将这些样本加入训练集，更新为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\theta_{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>。</li>
</ol>
</li>
</ul>
<p><strong>本质</strong>：这是在最大化<strong>信息增益（Information Gain）</strong>。通过专注于模型“最困惑”或“最自负但错误”的区域，由于 Loss 很大，反向传播时的梯度也最大，从而用最少的标注成本实现最大的性能提升。</p>
<h4 id="2-评分映射product-vs-min-联合概率-vs-短板效应">2. 评分映射：Product vs. Min (联合概率 vs. 短板效应)</h4>
<p><strong>学术背景：</strong></p>
<p>如何将序列化的局部评分 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">v_1, ..., v_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 聚合为全局评分 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow><mi>p</mi><mi>a</mi><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Score_{path}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>？</p>
<ul>
<li>
<p><strong>Option A: Minimum (短板效应)</strong></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mtext>Score</mtext><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub><mo>=</mo><munder><mi>min</mi><mo>⁡</mo><mi>k</mi></munder><msub><mi>v</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\text{Score}_{min} = \min_{k} v_k
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord">Score</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.419968em;vertical-align:-0.7521079999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7521079999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li><strong>逻辑</strong>：这是基于 <strong>逻辑合取（Logical Conjunction）</strong> 的假设。在严格的演绎推理中，只要有一步是错的，整个证明就是错的。这符合数学的严谨性。</li>
<li><strong>缺陷</strong>：PRM 本身是一个由神经网络拟合的概率模型，存在 <strong>噪声（Aleatoric Uncertainty）</strong>。如果 PRM 误判了某一步（False Positive），给出了一个极低的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">v_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，那么整条正确的路径就被“冤杀”了。</li>
</ul>
</li>
<li>
<p><strong>Option B: Product (联合概率)</strong></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mtext>Score</mtext><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>d</mi></mrow></msub><mo>=</mo><munderover><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>P</mi><mo>(</mo><msub><mi>l</mi><mi>k</mi></msub><mo>=</mo><mtext>correct</mtext><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mrow><mo>&lt;</mo><mi>k</mi></mrow></msub><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mtext>Whole Chain is Correct</mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">\text{Score}_{prod} = \prod_{k=1}^K P(l_k=\text{correct} | s_{&lt;k}) = P(\text{Whole Chain is Correct})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord text"><span class="mord">Score</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1304490000000005em;vertical-align:-1.302113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">correct</span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999985em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">Whole Chain is Correct</span></span><span class="mclose">)</span></span></span></span></span></p>
<p>或者在对数域计算（数值更稳定）：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mtext>Score</mtext><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>u</mi><mi>m</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>log</mi><mo>⁡</mo><msub><mi>v</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\text{Score}_{log\_sum} = \sum_{k=1}^K \log v_k
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05033em;vertical-align:-0.367em;"></span><span class="mord"><span class="mord text"><span class="mord">Score</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.367em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1304490000000005em;vertical-align:-1.302113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li><strong>逻辑</strong>：这是基于 <strong>独立同分布（i.i.d.）</strong> 或 <strong>马尔可夫链</strong> 的近似。它表示整条路径全对的联合概率。</li>
<li><strong>优势（Why OpenAI chose this）</strong>：它具有 <strong>平滑性（Smoothing）</strong>。
<ul>
<li>如果一条路径有 10 步，9 步是 0.99，1 步是 0.8（稍微不确定），Product 依然会给出一个不错的总分。</li>
<li>而 Min 会直接把分数锁死在 0.8。</li>
<li>OpenAI 的实验表明，由于 PRM 自身的不完美，使用 Product 可以容忍单步的预测噪声，从而在 Best-of-N 搜索中召回更多正确的解。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="第二部分通俗易懂的解释-layman-explanationshutterstock-explore">第二部分：通俗易懂的解释 (Layman Explanation)<img src="https://encrypted-tbn1.gstatic.com/licensed-image?q=tbn:ANd9GcT_rWX3AmcId91SdBEga2NEwUwvlXuSRP8d0nwXHrkP9pLNf9xgi8RlW2u4VOEbkMWc4VUpUH97yCvyM8ZDjALoBfsrH2NwBo6JMoE_egjcPHo85s8" alt="Image of active learning loop diagram" loading="lazy">Shutterstock Explore</h3>
<h4 id="1-主动学习专门挑刺头学生">1. 主动学习：专门挑“刺头”学生</h4>
<p>想象你是一个批改作文的老师（人工标注员），你要训练一个 AI 助教（PRM）。</p>
<ul>
<li>
<p><strong>普通做法（Random Sampling）</strong>：你随机抽查 AI 助教批改的作业。结果发现它改的“1+1=2”都是对的。你教了它半天，它也没学到新东西，因为这些太简单了。</p>
</li>
<li>
<p><strong>OpenAI 的做法（Hard Negatives）</strong>：</p>
<p>你对 AI 助教说：“把那些<strong>你觉得写得特别好、打了满分，但最后答案却是错的</strong>作文拿给我看。”</p>
<ul>
<li>这时候你发现，AI 助教被学生的“一本正经胡说八道”给骗了。</li>
<li>你指着那个具体的错误步骤说：“看清楚，这里逻辑不通，别被它的修辞骗了！”</li>
<li><strong>效果</strong>：专门纠正 AI 最容易犯错、最自信的错误，学习效率翻倍。</li>
</ul>
</li>
</ul>
<h4 id="2-评分方式是选完美主义者还是综合素质">2. 评分方式：是选“完美主义者”还是“综合素质”？</h4>
<p>我们要评价一个体操运动员的一套动作（一条思维链）：</p>
<ul>
<li><strong>最小值策略 (Minimum, 短板效应)</strong>：
<ul>
<li>评委非常严苛。你做了 10 个高难度动作，前 9 个都是世界级水平（满分），但第 10 个动作落地时稍微晃了一下（60分）。</li>
<li><strong>结果</strong>：评委直接给你打 60 分。因为你“有一处不完美”。</li>
<li><strong>问题</strong>：这太容易“误杀”好苗子了，万一评委眼花了呢？</li>
</ul>
</li>
<li><strong>乘积策略 (Product, 联合概率)</strong>：
<ul>
<li>评委看的是“整体流畅度”。你前 9 个动作完美，第 10 个小失误。</li>
<li><strong>结果</strong>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0.99</mn><mo>×</mo><mn>0.99</mn><mo>×</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>×</mo><mn>0.6</mn><mo>≈</mo><mn>0.55</mn></mrow><annotation encoding="application/x-tex">0.99 \times 0.99 \times ... \times 0.6 \approx 0.55</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">5</span></span></span></span>（如果不取对数）。虽然分低了点，但比纯粹的 0.6 要更能反映整体水平。</li>
<li><strong>OpenAI 的发现</strong>：因为 AI 评委（PRM）自己有时候也会看走眼，用“乘积”的方式比较宽容，能把那些<strong>整体逻辑很顺畅、只是某一步稍显模糊</strong>的好答案给捞回来，而不是因为一步的误判就直接枪毙。</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h3 id="3-手撕代码重点与实现-whiteboard-coding-focus">3. 手撕代码重点与实现 (Whiteboard Coding Focus)</h3>
<p>在面试中，面试官通常不会让你写数据标注的 Pipeline，而是让你<strong>实现 PRM 的前向传播（Forward）逻辑</strong>，或者是<strong>基于 PRM 的搜索算法（如 Beam Search 或 Best-of-N）</strong>。</p>
<h4 id="重点标注必须死记硬背的核心逻辑"><strong>重点标注（必须死记硬背的核心逻辑）</strong></h4>
<ol>
<li><strong>Step 分割</strong>：如何识别 step 的边界（通常是 <code>\n</code> 或特定 token）。</li>
<li><strong>Gather 操作</strong>：LLM 输出是 <code>(Batch, Seq_Len, Hidden_Dim)</code>，你必须准确地把<strong>每一步最后一个 Token</strong> 对应的 Hidden State 提取出来，送入 Reward Head。<strong>这是手撕代码最容易写错的地方！</strong></li>
</ol>
<p>这是一个非常关键的环节。在面试“手撕代码”时，<strong>面试官考察的不是你能不能写出几百行的工程代码，而是你对 Tensor 维度的敏感度</strong>。</p>
<p>对于 PRM（过程奖励模型），<strong>最核心、最容易挂人</strong>的逻辑就是：<strong>如何从一堆 Token 中，精准地把每一个步骤（Step）结束位置的 Hidden State 抠出来</strong>。</p>
<p>以下是两段你需要<strong>死记硬背</strong>的代码。第一段是模型前向传播（核心考点），第二段是预处理（Step 边界识别）。</p>
<hr>
<h3 id="核心考点一prm-模型前向传播-the-gather-logic">核心考点一：PRM 模型前向传播 (The &quot;Gather&quot; Logic)</h3>
<p><strong>面试场景</strong>：面试官会在白板上画一个 <code>(Batch, Seq_Len, Hidden)</code> 的立方体，问你：“假设我知道了每一步结束的 index，怎么拿到对应的向量去算 Reward？”</p>
<p><strong>代码策略</strong>：不要用 <code>for</code> 循环！要用 <strong>Vectorized Indexing (花式索引)</strong> 或 <code>torch.gather</code>。推荐用 <strong>花式索引</strong>，代码更短，更容易写对。</p>
<p>Python</p>
<pre><code>import torch
import torch.nn as nn

class ProcessRewardModel(nn.Module):
    def __init__(self, base_model, hidden_dim, num_classes=3):
        super().__init__()
        self.base_model = base_model  # 比如 transformers 的 AutoModel
        # 输出维度通常是 3 (Positive, Negative, Neutral) 或 1 (Scalar Score)
        self.reward_head = nn.Linear(hidden_dim, num_classes)

    def forward(self, input_ids, attention_mask, step_end_indices):
        &quot;&quot;&quot;
        核心参数解释：
        input_ids: [Batch, Seq_Len]
        step_end_indices: [Batch, Max_Steps] 
                          存储了每个step最后一个token的下标。
                          Padding 部分通常填 -1 或 0 (需配合 mask 处理)。
        &quot;&quot;&quot;
        
        # 1. 跑 Base Model，拿所有 Token 的向量
        # outputs: [Batch, Seq_Len, Hidden_Dim]
        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = outputs.last_hidden_state 
        
        # ==========================================
        # ★★★ 必须默写：Batch Gather 核心逻辑 ★★★
        # ==========================================
        
        # 目的：从 [Batch, Seq, Hidden] 中取出 [Batch, Steps, Hidden]
        
        # 技巧：构造 Batch 索引辅助张量
        # batch_idx shape: [Batch, 1] -&gt; 广播成 [Batch, Max_Steps]
        batch_size, max_steps = step_end_indices.shape
        batch_idx = torch.arange(batch_size, device=input_ids.device).unsqueeze(1)
        
        # 处理 Padding (-1 的情况)：
        # 如果 index 是 -1，为了防止报错，先把它换成 0，算完后再 mask 掉
        valid_mask = (step_end_indices != -1)
        safe_indices = step_end_indices.clone()
        safe_indices[~valid_mask] = 0  # 将 -1 替换为 0，防止越界
        
        # 核心提取代码 (Fancy Indexing)
        # 这里的原理是: result[i, j, :] = last_hidden_state[i, safe_indices[i, j], :]
        step_hidden_states = last_hidden_state[batch_idx, safe_indices] 
        
        # ==========================================
        #              逻辑结束
        # ==========================================

        # 2. 过全连接层计算 Logits
        # logits: [Batch, Max_Steps, Num_Classes]
        logits = self.reward_head(step_hidden_states)
        
        return logits, valid_mask
</code></pre>
<h4 id="面试官追问细节-checkpoints"><strong>💡 面试官追问细节 (Checkpoints)</strong></h4>
<ol>
<li><strong>问</strong>：为什么 <code>last_hidden_state[batch_idx, safe_indices]</code> 能工作？
<ul>
<li><strong>答</strong>：这是 PyTorch 的 <strong>Advanced Indexing</strong> 机制。<code>batch_idx</code> 是 <code>(B, 1)</code>，<code>safe_indices</code> 是 <code>(B, S)</code>。PyTorch 会自动把 <code>batch_idx</code> 广播成 <code>(B, S)</code>，然后和 <code>safe_indices</code> 配对，取出对应的向量。</li>
</ul>
</li>
<li><strong>问</strong>：<code>step_end_indices</code> 里的 <code>-1</code> 如果不处理会怎样？
<ul>
<li><strong>答</strong>：会报 <code>IndexError: index out of bounds</code>。这也是工程实现最容易崩的地方，必须用 <code>clone</code> 和 mask 保护起来。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="核心考点二step-分割-step-splitting">核心考点二：Step 分割 (Step Splitting)</h3>
<p><strong>面试场景</strong>：面试官问：“你刚才用的 <code>step_end_indices</code> 是怎么来的？假设我的分隔符是 <code>\n\n</code>，给我写个函数处理一下。”</p>
<p><strong>代码策略</strong>：利用 <code>tokenizer</code> 的 <code>encode</code> 结果找 ID。</p>
<p>Python</p>
<pre><code>def find_step_boundaries(tokenizer, text_batch, separator=&quot;\n\n&quot;):
    &quot;&quot;&quot;
    text_batch: List[str] -&gt; [&quot;Step 1...\n\nStep 2...&quot;, ...]
    &quot;&quot;&quot;
    # 1. 获取分隔符的 Token ID (注意：有些 tokenizer 会加空格，需仔细 check)
    # 这里假设 separator 对应的 ID 是单 token 或固定序列
    sep_id = tokenizer.encode(separator, add_special_tokens=False)[0] 
    
    batch_indices = []
    
    # 对 Batch 中每条数据进行处理
    inputs = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)
    input_ids = inputs['input_ids'] # [Batch, Seq_Len]
    
    for i in range(input_ids.shape[0]):
        # 找到所有等于 sep_id 的位置
        # (input_ids[i] == sep_id).nonzero() 返回形状 [Num_Found, 1]
        # squeeze 后变成 [Num_Found]
        sep_positions = (input_ids[i] == sep_id).nonzero(as_tuple=True)[0]
        
        # 将 Tensor 转 list 存起来
        batch_indices.append(sep_positions)
        
    # 注意：这就得到了每一步结束的位置。
    # 实际工程中，需要 Pad 这些 list 使得它们长度一致，才能转成 Tensor
    return batch_indices, inputs
</code></pre>
<h4 id="工程坑点-production-details"><strong>💡 工程坑点 (Production Details)</strong></h4>
<ul>
<li><strong>Tokenization 陷阱</strong>：像 LLaMA 的 Tokenizer，<code>\n</code> 单独是一个 ID (13)，但如果 <code>\n</code> 前面有字，可能会合并。
<ul>
<li><em>满分回答</em>：在实际训练 PRM 时，通常会在数据预处理阶段，<strong>通过字符串匹配（Regex）找到字符的 offset</strong>，然后利用 HuggingFace Tokenizer 的 <code>char_to_token</code> 方法来映射到 Token Index，这比直接在 ID 层面找更稳健。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="总结白板怎么写">总结：白板怎么写？</h3>
<p>如果面试时间紧，只需要写最核心的 <strong>Forward</strong>。记住这个 <strong>&quot;三行魔咒&quot;</strong>：</p>
<ol>
<li><strong>Make Batch Index</strong>: <code>batch_idx = torch.arange(B).unsqueeze(1)</code></li>
<li><strong>Mask Safety</strong>: <code>indices[indices == -1] = 0</code></li>
<li><strong>Fancy Indexing</strong>: <code>h_steps = hidden[batch_idx, indices]</code></li>
</ol>
<p>写出这三行，面试官就知道你是真的懂 PyTorch 底层 Tensor 操作，而不是只会被调包的 API Caller。</p>
<h4 id="工程细节"><strong>工程细节</strong></h4>
<ul>
<li><strong>Tokenization</strong>：不同的 Tokenizer 对换行符 <code>\n</code> 的处理不同。有的会把 <code>\n</code> 单独成 token，有的会合并。必须确保 <code>step_end_indices</code> 指向的是该步骤真正结束的那个 token。</li>
<li><strong>Class Imbalance</strong>：在训练 PRM 时，正样本（正确步骤）通常远多于负样本（错误步骤），或者相反。工程上需要使用 Weighted Cross Entropy 或 Focal Loss。</li>
<li><strong>Inference 缓存</strong>：在做 Tree Search 时，如果父节点已经计算过 KV Cache，子节点的 PRM 计算应该复用 KV Cache，否则推理成本爆炸。</li>
</ul>
<hr>
<h3 id="4-面试高频考察点-interview-checkpoints">4. 面试高频考察点 (Interview Checkpoints)</h3>
<h4 id="q1-prm-相比-orm最大的劣势是什么"><strong>Q1: PRM 相比 ORM，最大的劣势是什么？</strong></h4>
<ul>
<li><strong>满分回答</strong>：最大的劣势是<strong>数据标注成本（Data Annotation Cost）</strong>。ORM 只需要最终答案（可以通过编译器或数学求解器自动验证），而 PRM 需要人类专家对思维链的每一步进行核查。</li>
<li><strong>佐证</strong>：OpenAI 在论文中不得不使用了 Active Learning 来降低标注量，并发布了 <code>PRM800K</code> 数据集，这侧面说明了数据构建的难度。</li>
</ul>
<h4 id="q2-在-inference-阶段如何利用-prm-来提升效果search-strategy"><strong>Q2: 在 Inference 阶段，如何利用 PRM 来提升效果？(Search Strategy)</strong></h4>
<ul>
<li><strong>满分回答</strong>：最常用的方法是 <strong>Best-of-N (Rejection Sampling)</strong> 或 <strong>Tree Search (如 MCTS)</strong>。
<ul>
<li><strong>Best-of-N</strong>：生成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span> 个完整解，用 PRM 给每个解打分（通常是所有 step 分数的乘积），选最高的。</li>
<li><strong>Tree Search</strong>：在每生成一步时，用 PRM 评估当前分支的价值，如果分数过低直接剪枝（Pruning），分数高则继续扩展。这能大幅减少无效计算。</li>
</ul>
</li>
<li><strong>追问</strong>：PRM 打分是乘积好还是最小值好？（参考论文结论：通常乘积 Product 或 Sum of Log-probs 更好，因为它平滑了单步的误判）。</li>
</ul>
<h4 id="q3-为什么-prm-被认为比-orm-更适合对齐alignment任务"><strong>Q3: 为什么 PRM 被认为比 ORM 更适合对齐（Alignment）任务？</strong></h4>
<ul>
<li><strong>满分回答</strong>：除了性能，PRM 提供了更好的<strong>可解释性（Interpretability）和安全性（Safety）</strong>。ORM 像一个黑盒，可能鼓励模型通过欺骗（Deception）或走捷径来获得奖励。PRM 强制模型每一步都符合人类逻辑，减少了“奖励黑客（Reward Hacking）”的风险。</li>
</ul>
<hr>
<h3 id="5-场景与演进-sota-evolution">5. 场景与演进 (SOTA &amp; Evolution)</h3>
<h4 id="业务场景"><strong>业务场景</strong></h4>
<ul>
<li><strong>数学解题（Math Solving）</strong>：这是 PRM 最早也是最成功的战场（如 GSM8K, MATH 数据集）。</li>
<li><strong>代码生成（Code Generation）</strong>：每写一个函数块或逻辑段落，就进行一次检查。</li>
<li><strong>复杂 Agent 规划</strong>：当 Agent 需要调用多个 API 完成任务时，PRM 用于监控每一步 Tool Call 是否合理。</li>
</ul>
<h4 id="sota-演进"><strong>SOTA 演进</strong></h4>
<ul>
<li><strong>目前地位</strong>：PRM 是目前提升 LLM 推理能力最有效的**Test-time Scaling（推理时扩展）**技术之一。它是 OpenAI <strong>o1/Strawberry</strong> 模型背后的核心假设技术之一。</li>
<li><strong>改进变体 (Variants)</strong>：
<ol>
<li><strong>Qwen-Math / DeepSeek-Math</strong>：国内大厂（阿里、深度求索）在后续工作中，探索了<strong>无需人工标注的自动化 PRM</strong>。利用 Monte Carlo 采样生成多条路径，根据最终答案自动反推步骤的正确性（虽有噪声，但量大）。</li>
<li><strong>Outcome-supervision to Process-supervision (O2P)</strong>：利用强大的教师模型（GPT-4）去自动化标注过程数据，以此来蒸馏小模型的 PRM。</li>
<li><strong>Step-Level Value Model</strong>：在 RLHF (PPO) 中，PRM 实际上充当了更密集的 Value Model，指导 Policy 模型的更新，这比传统的 Token-level KL 约束更具指向性。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="总结">总结</h3>
<p>在面试中，如果你能讲清楚 <strong>&quot;Let's Verify Step by Step&quot;</strong> 中 Active Learning 的数据构建策略，并在白板上写出 <strong>Gather Hidden States</strong> 的关键代码，同时点出它在 <strong>MCTS/Best-of-N</strong> 中的应用，你就能展现出 T7/P8 级别的技术视野。</p>
<p>祝面试顺利！</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#1-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AE%BA%E6%96%87%E6%BA%AF%E6%BA%90-concept-paper-roots">1. 核心概念与论文溯源 (Concept &amp; Paper Roots)</a>
<ul>
<li><a href="#%E8%AE%BA%E6%96%87%E5%BC%95%E7%94%A8"><strong>论文引用</strong></a></li>
<li><a href="#%E6%9C%AC%E8%B4%A8%E6%A6%82%E6%8B%AC"><strong>本质概括</strong></a></li>
<li><a href="#%E7%97%9B%E7%82%B9%E8%A7%A3%E5%86%B3"><strong>痛点解决</strong></a></li>
</ul>
</li>
<li><a href="#2-%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A8%E5%AF%BC-mathematical-underpinning">2. 数学原理与推导 (Mathematical Underpinning)</a>
<ul>
<li><a href="#%E6%A0%B8%E5%BF%83%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%AF%B9%E6%AF%94"><strong>核心定义与对比</strong></a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%B7%B1%E5%BA%A6%E5%AD%A6%E6%9C%AF%E8%A7%A3%E6%9E%90-academic-deep-dive">第一部分：深度学术解析 (Academic Deep Dive)</a>
<ul>
<li><a href="#1-%E6%95%B0%E5%AD%A6%E6%9C%AC%E8%B4%A8%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E4%B8%8E%E6%9C%9F%E6%9C%9B%E6%9C%80%E5%A4%A7%E5%8C%96">1. 数学本质：策略梯度与期望最大化</a></li>
<li><a href="#2-orm-%E7%9A%84%E4%B8%A4%E7%A7%8D%E8%AE%AD%E7%BB%83%E8%8C%83%E5%BC%8F">2. ORM 的两种训练范式</a></li>
<li><a href="#3-%E6%A0%B8%E5%BF%83%E7%BC%BA%E9%99%B7%E6%97%B6%E9%97%B4%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D%E9%97%AE%E9%A2%98-temporal-credit-assignment">3. 核心缺陷：时间信用分配问题 (Temporal Credit Assignment)</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%A7%A3%E9%87%8A-layman-explanation">第二部分：通俗易懂的解释 (Layman Explanation)</a>
<ul>
<li><a href="#1-%E5%9C%BA%E6%99%AF%E7%B1%BB%E6%AF%94%E5%8F%AA%E7%9C%8B%E7%AD%94%E6%A1%88%E7%9A%84%E8%80%83%E8%AF%95">1. 场景类比：只看答案的考试</a></li>
<li><a href="#2-%E9%82%A3%E4%B8%AA%E5%A4%8D%E6%9D%82%E7%9A%84%E5%85%AC%E5%BC%8F%E5%9C%A8%E8%AF%B4%E4%BB%80%E4%B9%88">2. 那个复杂的公式在说什么？</a></li>
<li><a href="#3-%E8%BF%99%E7%A7%8D%E6%96%B9%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81-prm">3. 这种方法的问题（为什么我们需要 PRM？）</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%B7%B1%E5%BA%A6%E5%AD%A6%E6%9C%AF%E8%A7%A3%E6%9E%90-academic-deep-dive-2">第一部分：深度学术解析 (Academic Deep Dive)</a>
<ul>
<li><a href="#1-%E5%BB%BA%E6%A8%A1token-%E7%BA%A7%E5%88%AB%E7%9A%84%E5%88%A4%E5%88%AB%E4%BB%BB%E5%8A%A1-discriminative-task">1. 建模：Token 级别的判别任务 (Discriminative Task)</a></li>
</ul>
</li>
<li><a href="#1-%E6%A0%B8%E5%BF%83%E5%AE%9A%E4%B9%89%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%A4%E5%88%AB%E5%BC%8F%E5%BB%BA%E6%A8%A1">1. 核心定义：什么是判别式建模？</a></li>
<li><a href="#2-%E7%BB%93%E5%90%88%E4%BD%A0%E7%9A%84%E5%85%AC%E5%BC%8F%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90">2. 结合你的公式深度解析</a></li>
<li><a href="#3-%E9%9D%A2%E8%AF%95%E5%BF%85%E8%80%83%E5%88%A4%E5%88%AB%E5%BC%8F-vs-%E7%94%9F%E6%88%90%E5%BC%8F-discriminative-vs-generative">3. 面试必考：判别式 vs. 生成式 (Discriminative vs. Generative)</a>
<ul>
<li><a href="#%E7%BB%93%E5%90%88-prm-%E5%9C%BA%E6%99%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E7%90%86%E8%A7%A3">结合 PRM 场景的深度理解：</a></li>
</ul>
</li>
<li><a href="#4-%E4%B8%BA%E4%BB%80%E4%B9%88-prm-%E8%A6%81%E7%94%A8%E5%88%A4%E5%88%AB%E5%BC%8F">4. 为什么 PRM 要用判别式？</a>
<ul>
<li><a href="#2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1-mle">2. 损失函数解析：最大似然估计 (MLE)</a></li>
<li><a href="#3-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E5%AF%86%E9%9B%86%E4%BF%A1%E5%8F%B7-dense-signal">3. 为什么是“密集信号” (Dense Signal)？</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%A7%A3%E9%87%8A-layman-explanation-2">第二部分：通俗易懂的解释 (Layman Explanation)</a>
<ul>
<li><a href="#1-%E5%9C%BA%E6%99%AF%E7%B1%BB%E6%AF%94gps-%E5%AF%BC%E8%88%AA">1. 场景类比：GPS 导航</a></li>
<li><a href="#2-prm-%E5%88%B0%E5%BA%95%E5%9C%A8%E7%AE%97%E4%BB%80%E4%B9%88">2. PRM 到底在算什么？</a></li>
<li><a href="#3-%E6%A0%B8%E5%BF%83%E4%BB%B7%E5%80%BC">3. 核心价值</a></li>
<li><a href="#%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E8%A7%86%E8%A7%92%E4%B8%8E-trick"><strong>论文中的数学视角与 Trick</strong></a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%B7%B1%E5%BA%A6%E5%AD%A6%E6%9C%AF%E8%A7%A3%E6%9E%90-academic-deep-dive-3">第一部分：深度学术解析 (Academic Deep Dive)</a>
<ul>
<li><a href="#1-active-learning-hard-negatives-%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%9A%BE%E8%B4%9F%E6%A0%B7%E6%9C%AC%E6%8C%96%E6%8E%98">1. Active Learning &amp; Hard Negatives (主动学习与难负样本挖掘)</a></li>
<li><a href="#2-%E8%AF%84%E5%88%86%E6%98%A0%E5%B0%84product-vs-min-%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87-vs-%E7%9F%AD%E6%9D%BF%E6%95%88%E5%BA%94">2. 评分映射：Product vs. Min (联合概率 vs. 短板效应)</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%A7%A3%E9%87%8A-layman-explanationshutterstock-explore">第二部分：通俗易懂的解释 (Layman Explanation)!Image of active learning loop diagramShutterstock Explore</a>
<ul>
<li><a href="#1-%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E9%97%A8%E6%8C%91%E5%88%BA%E5%A4%B4%E5%AD%A6%E7%94%9F">1. 主动学习：专门挑“刺头”学生</a></li>
<li><a href="#2-%E8%AF%84%E5%88%86%E6%96%B9%E5%BC%8F%E6%98%AF%E9%80%89%E5%AE%8C%E7%BE%8E%E4%B8%BB%E4%B9%89%E8%80%85%E8%BF%98%E6%98%AF%E7%BB%BC%E5%90%88%E7%B4%A0%E8%B4%A8">2. 评分方式：是选“完美主义者”还是“综合素质”？</a></li>
</ul>
</li>
<li><a href="#3-%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81%E9%87%8D%E7%82%B9%E4%B8%8E%E5%AE%9E%E7%8E%B0-whiteboard-coding-focus">3. 手撕代码重点与实现 (Whiteboard Coding Focus)</a>
<ul>
<li><a href="#%E9%87%8D%E7%82%B9%E6%A0%87%E6%B3%A8%E5%BF%85%E9%A1%BB%E6%AD%BB%E8%AE%B0%E7%A1%AC%E8%83%8C%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91"><strong>重点标注（必须死记硬背的核心逻辑）</strong></a></li>
</ul>
</li>
<li><a href="#%E6%A0%B8%E5%BF%83%E8%80%83%E7%82%B9%E4%B8%80prm-%E6%A8%A1%E5%9E%8B%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD-the-gather-logic">核心考点一：PRM 模型前向传播 (The &quot;Gather&quot; Logic)</a>
<ul>
<li><a href="#%E9%9D%A2%E8%AF%95%E5%AE%98%E8%BF%BD%E9%97%AE%E7%BB%86%E8%8A%82-checkpoints"><strong>💡 面试官追问细节 (Checkpoints)</strong></a></li>
</ul>
</li>
<li><a href="#%E6%A0%B8%E5%BF%83%E8%80%83%E7%82%B9%E4%BA%8Cstep-%E5%88%86%E5%89%B2-step-splitting">核心考点二：Step 分割 (Step Splitting)</a>
<ul>
<li><a href="#%E5%B7%A5%E7%A8%8B%E5%9D%91%E7%82%B9-production-details"><strong>💡 工程坑点 (Production Details)</strong></a></li>
</ul>
</li>
<li><a href="#%E6%80%BB%E7%BB%93%E7%99%BD%E6%9D%BF%E6%80%8E%E4%B9%88%E5%86%99">总结：白板怎么写？</a>
<ul>
<li><a href="#%E5%B7%A5%E7%A8%8B%E7%BB%86%E8%8A%82"><strong>工程细节</strong></a></li>
</ul>
</li>
<li><a href="#4-%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91%E8%80%83%E5%AF%9F%E7%82%B9-interview-checkpoints">4. 面试高频考察点 (Interview Checkpoints)</a>
<ul>
<li><a href="#q1-prm-%E7%9B%B8%E6%AF%94-orm%E6%9C%80%E5%A4%A7%E7%9A%84%E5%8A%A3%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88"><strong>Q1: PRM 相比 ORM，最大的劣势是什么？</strong></a></li>
<li><a href="#q2-%E5%9C%A8-inference-%E9%98%B6%E6%AE%B5%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8-prm-%E6%9D%A5%E6%8F%90%E5%8D%87%E6%95%88%E6%9E%9Csearch-strategy"><strong>Q2: 在 Inference 阶段，如何利用 PRM 来提升效果？(Search Strategy)</strong></a></li>
<li><a href="#q3-%E4%B8%BA%E4%BB%80%E4%B9%88-prm-%E8%A2%AB%E8%AE%A4%E4%B8%BA%E6%AF%94-orm-%E6%9B%B4%E9%80%82%E5%90%88%E5%AF%B9%E9%BD%90alignment%E4%BB%BB%E5%8A%A1"><strong>Q3: 为什么 PRM 被认为比 ORM 更适合对齐（Alignment）任务？</strong></a></li>
</ul>
</li>
<li><a href="#5-%E5%9C%BA%E6%99%AF%E4%B8%8E%E6%BC%94%E8%BF%9B-sota-evolution">5. 场景与演进 (SOTA &amp; Evolution)</a>
<ul>
<li><a href="#%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF"><strong>业务场景</strong></a></li>
<li><a href="#sota-%E6%BC%94%E8%BF%9B"><strong>SOTA 演进</strong></a></li>
</ul>
</li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://Alive-mk.github.io/post/tot-tree-of-thoughts-he-got-graph-of-thoughts/">
              <h3 class="post-title">
                ToT (Tree of Thoughts) 和 GoT (Graph of Thoughts) 
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://Alive-mk.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
