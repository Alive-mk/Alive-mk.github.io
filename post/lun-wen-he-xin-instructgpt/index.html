<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>论文核心：InstructGPT  | Alive-mk</title>
<link rel="shortcut icon" href="https://Alive-mk.github.io/favicon.ico?v=1770951170092">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://Alive-mk.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="论文核心：InstructGPT  | Alive-mk - Atom Feed" href="https://Alive-mk.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="论文核心：InstructGPT 详解
1. 核心问题：对齐（Alignment）
论文开篇指出了一个关键矛盾：大模型（如 GPT-3）的目标与用户的意图不匹配。

预训练目标：预测下一个 token（Next Token Predicti..." />
    <meta name="keywords" content="实习" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://Alive-mk.github.io">
  <img class="avatar" src="https://Alive-mk.github.io/images/avatar.png?v=1770951170092" alt="">
  </a>
  <h1 class="site-title">
    Alive-mk
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              论文核心：InstructGPT 
            </h2>
            <div class="post-info">
              <span>
                2026-01-30
              </span>
              <span>
                48 min read
              </span>
              
                <a href="https://Alive-mk.github.io/tag/pt1Ejsp1Pa/" class="post-tag">
                  # 实习
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <h3 id="论文核心instructgpt-详解"><strong>论文核心：InstructGPT 详解</strong></h3>
<h4 id="1-核心问题对齐alignment"><strong>1. 核心问题：对齐（Alignment）</strong></h4>
<p>论文开篇指出了一个关键矛盾：<strong>大模型（如 GPT-3）的目标与用户的意图不匹配。</strong></p>
<ul>
<li><strong>预训练目标</strong>：预测下一个 token（Next Token Prediction）。模型只是在模仿互联网上的文本，不管这些文本是好是坏。</li>
<li><strong>用户意图</strong>：用户希望模型是**有用（Helpful）、诚实（Honest）和无害（Harmless）**的。</li>
<li><strong>后果</strong>：单纯把模型做大（Scaling up）并不能让它更听话，反而可能导致它生成虚假信息（Hallucination）、有毒内容或无法遵循指令。</li>
</ul>
<p><strong>InstructGPT 的目标</strong>就是通过引入<strong>人类反馈（Human Feedback）</strong>，将模型的行为与人类意图“对齐”。</p>
<hr>
<figure data-type="image" tabindex="1"><img src="https://Alive-mk.github.io/post-images/1769938274839.png" alt="" loading="lazy"></figure>
<h4 id="2-技术路线rlhf-的三个阶段-图解-figure-2"><strong>2. 技术路线：RLHF 的三个阶段 (图解 Figure 2)</strong></h4>
<p>这是全篇论文的精华，也是所有现代对话模型（Chat Models）的标准制作流程。</p>
<p>好的，我们现在深入</p>
<p><strong>阶段 1：监督微调 (SFT - Supervised Fine-Tuning)</strong>。</p>
<p>如果把预训练（Pre-training）比作让模型“通读图书馆”学会了所有的知识，那么 SFT 就是让模型“参加岗前培训”，学会如何像一个助手一样<strong>规范地</strong>回答问题。</p>
<p>以下是关于 SFT 的<strong>深度教学</strong>，包含数据工程细节、训练原理以及论文中的关键发现。</p>
<hr>
<h3 id="一-核心概念行为克隆-behavior-cloning">一、 核心概念：行为克隆 (Behavior Cloning)</h3>
<p>SFT 的本质是<strong>行为克隆</strong>。模型不再是漫无目的地预测下一个词，而是模仿人类在特定场景下的对话行为。</p>
<ul>
<li><strong>输入 (x)</strong>: 用户指令（Prompt）。</li>
<li><strong>输出 (y)</strong>: 期望的理想回答（Demonstration）。</li>
<li><strong>目标</strong>: 最大化 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">P(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>，即在给定指令 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 的情况下，生成回答 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 的概率。</li>
</ul>
<hr>
<h3 id="二-数据工程sft-的燃料">二、 数据工程：SFT 的燃料</h3>
<p>在 InstructGPT 论文中，数据的质量比数量更重要。SFT 数据集的构建极其讲究。</p>
<h4 id="1-数据来源与构成">1. 数据来源与构成</h4>
<p>InstructGPT 的 SFT 数据集并不大（只有约 13,000 条数据 ），但非常精细。它由两部分组成：</p>
<ul>
<li><strong>标签员编写 (Labeler-written)</strong>:
<ul>
<li><strong>Plain</strong>: 让标注员随意想一个任务并写出好回答（保证多样性）。</li>
<li><strong>Few-shot</strong>: 给出一个指令和几个示例（Query/Response pairs）。</li>
<li><strong>User-based</strong>: 基于 OpenAI API 的申请等待列表中的用例（Use-cases）编写 。</li>
</ul>
</li>
<li><strong>API 用户数据 (Customer prompts)</strong>: 从早期 API 使用记录中采样，并过滤掉个人敏感信息 (PII) 。</li>
</ul>
<h4 id="2-数据的多样性-diversity">2. 数据的多样性 (Diversity)</h4>
<p>为了让模型什么都能干，数据必须覆盖各种任务。论文统计了数据的分布（见 Table 1 ）：</p>
<ul>
<li><strong>生成 (Generation)</strong>: 45.6% (如：写故事、写邮件)</li>
<li><strong>开放问答 (Open QA)</strong>: 12.4% (如：为什么天空是蓝的？)</li>
<li><strong>头脑风暴 (Brainstorming)</strong>: 11.2% (如：给我的猫起个名字)</li>
<li><strong>聊天 (Chat)</strong>: 8.4%</li>
<li><strong>改写 (Rewrite)</strong>: 6.6%</li>
<li><strong>摘要 (Summarization)</strong>: 4.2%</li>
<li><strong>分类 (Classification)</strong>: 3.5%</li>
<li><strong>其他</strong>: 代码、提取等。</li>
</ul>
<h4 id="3-数据格式实战-jsonl">3. 数据格式实战 (JSONL)</h4>
<p>在实际代码中，你需要将数据整理成如下格式（通常称为 ChatML 格式）：</p>
<pre><code>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请解释一下相对论。&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;相对论是爱因斯坦提出的...&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;写一首关于秋天的诗。&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;秋风起兮白云飞...&quot;}]}
</code></pre>
<hr>
<h3 id="三-训练细节与-loss-计算-技术深挖">三、 训练细节与 Loss 计算 (技术深挖)</h3>
<p>这一部分是面试和实战中经常被问到的细节。</p>
<h4 id="1-loss-function-损失函数">1. Loss Function (损失函数)</h4>
<p>SFT 使用的依然是标准的 <strong>Causal Language Modeling (CLM) Loss</strong>（交叉熵损失）。</p>
<p>公式：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>θ</mi><mo>)</mo><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>t</mi></munder><mi>log</mi><mo>⁡</mo><mi>P</mi><mo>(</mo><msub><mi>u</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>u</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">L(\theta) = - \sum_{t} \log P(u_t | u_{&lt;t}, x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3000100000000003em;vertical-align:-1.250005em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">u</span></span></span></span> 是回答中的 token，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 是 prompt。</p>
<h4 id="2-关键技巧prompt-masking-loss-masking">2. 关键技巧：Prompt Masking (Loss Masking)</h4>
<p><strong>这是 SFT 与预训练最大的区别。</strong></p>
<ul>
<li>
<p><strong>预训练时</strong>：模型对所有 token 都要计算 Loss。</p>
</li>
<li>
<p><strong>SFT 时</strong>：我们<strong>只关心模型生成的回答 (Assistant output) 是否正确</strong>，而不关心模型是否能复述问题 (User prompt)。</p>
</li>
<li>
<p><strong>实现方式</strong>：</p>
<p>在计算 Loss 时，将 Prompt 部分的 <code>label</code> 设置为 <code>-100</code>（PyTorch 中 CrossEntropyLoss 的忽略索引）。</p>
<ul>
<li><strong>Input</strong>: <code>[User: 你好] [Assistant: 你好]</code></li>
<li><strong>Target</strong>: <code>[-100, -100, -100] [你, 好, EOS]</code></li>
<li><em>结果</em>：模型只学习如何生成回答，不会因为“背诵问题”而浪费梯度。</li>
</ul>
</li>
<li>
<p>论文中的超参数</p>
</li>
</ul>
<p>OpenAI 在训练 175B 模型时的设置（你可以作为参考）：</p>
<ul>
<li><strong>Epochs</strong>: 16 (这个数字在小数据集上比较大，通常我们会设 1-3)。</li>
<li><strong>Learning Rate Decay</strong>: 余弦衰减 (Cosine decay) 到 10%。</li>
<li><strong>Dropout</strong>: 0.2 (为了防止过拟合)。</li>
<li><strong>Optimizer</strong>: Adam。</li>
</ul>
<hr>
<h3 id="四-论文中的关键发现-insights">四、 论文中的关键发现 (Insights)</h3>
<p>InstructGPT 论文在 SFT 阶段有两个非常反直觉的发现，值得深入理解：</p>
<h4 id="1-过拟合悖论-the-overfitting-paradox">1. “过拟合”悖论 (The Overfitting Paradox)</h4>
<p>论文提到，SFT 模型在训练 <strong>1 个 epoch</strong> 后，验证集 Loss 就开始上升了（典型的过拟合迹象）。</p>
<ul>
<li><strong>通常做法</strong>：Early Stopping（立即停止训练）。</li>
<li><strong>OpenAI 做法</strong>：继续训练到 16 个 epoch。</li>
<li><strong>原因</strong>：虽然 Loss 上升了（模型开始死记硬背训练集的具体措辞），但人类对模型输出的<strong>评分 (Human Preference Ratings)</strong> 依然在提升 。</li>
<li><strong>结论</strong>：在对齐任务中，验证集 Loss 并不完全代表生成质量。</li>
</ul>
<h4 id="2-泛化能力-generalization">2. 泛化能力 (Generalization)</h4>
<p>SFT 后的模型展现出了惊人的泛化能力。虽然训练数据里 96% 都是英语 ，但模型在非英语任务和代码任务上也学会了“遵循指令”。这意味着模型学会的是“如何听话”这个底层逻辑，而不仅仅是语言模式。</p>
<hr>
<h3 id="五-实战代码演示如何实现-prompt-masking">五、 实战代码演示：如何实现 Prompt Masking</h3>
<p>我们在上一节代码的基础上，深入一下数据处理部分，看看 <code>DataCollator</code> 是如何工作的。这是使用 <code>trl</code> 库时的幕后逻辑。</p>
<pre><code>from transformers import AutoTokenizer
from trl import DataCollatorForCompletionOnlyLM

model_name = &quot;Qwen/Qwen1.5-0.5B&quot;
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 定义指令模板（Instruction Template）和回答模板（Response Template）
# 这一步是为了告诉训练器：哪里是提问的结束，哪里是回答的开始。
instruction_template = &quot;&lt;|im_start|&gt;user\n&quot;
response_template = &quot;&lt;|im_start|&gt;assistant\n&quot;

# 这是一个专门为 SFT 设计的数据整理器
# 它会自动把 instruction_template 及其之前的所有 token 的 Label 设为 -100
collator = DataCollatorForCompletionOnlyLM(
    instruction_template=instruction_template,
    response_template=response_template,
    tokenizer=tokenizer,
    mlm=False
)

# 假设的一个样本
sample_text = &quot;&lt;|im_start|&gt;user\nExplain AI&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nAI is Artificial Intelligence&lt;|im_end|&gt;&quot;

# 模拟 collator 的工作（简化版概念）
# Input IDs: [Start, user, Explain, AI, End, Start, assistant, AI, is, ...]
# Labels:    [-100, -100, -100, -100, -100, -100, -100,     AI, is, ...]
#               ^^^^^^^^^^^^ MASKED ^^^^^^^^^^^^^^^^      ^^ TRAIN ^^
</code></pre>
<h3 id="总结">总结</h3>
<p><strong>SFT 阶段自检清单：</strong></p>
<ol>
<li><strong>数据好不好？</strong> 是否包含多样化的任务？是否去除了低质量数据？</li>
<li><strong>格式对不对？</strong> 是否正确使用了 ChatML 格式（User/Assistant）？</li>
<li><strong>Mask 没 Mask？</strong> 训练时是否只计算了 Assistant 回答部分的 Loss？</li>
</ol>
<p>这一步完成后，你的模型已经“会说话”了，但它还不知道“好坏”。它可能会一本正经地胡说八道。为了解决这个问题，我们需要进入 <strong>阶段 2：Reward Model</strong>。</p>
<p>好的，我们现在深入 <strong>阶段 2：奖励模型训练 (Reward Model Training)</strong>。</p>
<p>如果说 <strong>SFT</strong> 是训练一个“厨师”学会做菜，那么 <strong>RM</strong> 就是训练一个“美食评论家”。这个评论家虽然自己不会做菜（不生成文本），但它的口味必须极好，能够精准地分辨出哪道菜（回答）更好吃。</p>
<p>在 InstructGPT 的流程中，这是将<strong>人类的主观偏好</strong>转化为<strong>机器可理解的数学信号</strong>的最关键一步。</p>
<hr>
<h3 id="一-核心逻辑为什么需要独立训练一个-rm">一、 核心逻辑：为什么需要独立训练一个 RM？</h3>
<p>你可能会问：<em>为什么不直接让人类给 PPO 阶段生成的回答打分？</em></p>
<ol>
<li><strong>效率（Scalability）</strong>：PPO 训练需要数百万次的迭代。让人类实时盯着模型生成的每一句话打分是不可能的。我们需要一个<strong>代理人（Proxy）</strong>——也就是 RM，来模仿人类的评分标准，没日没夜地给模型打分。</li>
<li><strong>一致性（Consistency）</strong>：人类会累，心情会变，标准会漂移。训练好的 RM 是一个固定的数学函数，它的评分标准是稳定的。</li>
</ol>
<hr>
<h3 id="二-数据工程如何构建比较数据集">二、 数据工程：如何构建“比较数据集”</h3>
<p>这是 RM 训练中最精妙的部分。OpenAI 没有让人类给一个回答打“8分”或“5分”，而是让人类做<strong>选择题</strong>。</p>
<h4 id="1-数据采集流程">1. 数据采集流程</h4>
<ol>
<li>
<p><strong>采样 (Sampling)</strong>: 拿出一个 Prompt（比如“解释什么是月亮”），让 SFT 模型生成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 个不同的回答（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">y_1, y_2, ..., y_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）。</p>
<ul>
<li><em>论文细节</em>：InstructGPT 通常设定 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">K=4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo>=</mo><mn>9</mn></mrow><annotation encoding="application/x-tex">K=9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">9</span></span></span></span> 。</li>
</ul>
</li>
<li>
<p><strong>标注 (Labeling)</strong>: 标注员看到的不是一个回答，而是一组回答。他们的任务是把这 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 个回答从好到坏进行<strong>排序 (Ranking)</strong>。</p>
<ul>
<li><em>例子</em>：对于生成的 A, B, C, D 四个回答，标注员认为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>&gt;</mo><mi>C</mi><mo>&gt;</mo><mi>A</mi><mo>&gt;</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">D &gt; C &gt; A &gt; B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>。</li>
</ul>
</li>
</ol>
<h4 id="2-为什么是排序ranking-vs-rating">2. 为什么是排序？(Ranking vs. Rating)</h4>
<p>正如你提到的，论文中明确指出：<strong>不同标注员的绝对打分标准差异巨大（Calibration 问题）</strong>。</p>
<ul>
<li>标注员甲可能很宽容，稍微好点就给 7 分。</li>
<li>标注员乙可能很严格，最好的也只给 5 分。</li>
<li><strong>但是</strong>，如果让他们比较 A 和 B 哪个更好，他们的**一致性（Agreement）**会高得多。</li>
</ul>
<h4 id="3-数据增强的魔法">3. 数据增强的魔法</h4>
<p>标注员只需要排一次序（比如排 4 个回答），我们就能获得 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mn>4</mn><mn>2</mn></mfrac><mo fence="true">)</mo></mrow><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">\binom{4}{2} = 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.245118em;vertical-align:-0.35001em;"></span><span class="mord"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8951079999999999em;"><span style="top:-2.3550000000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.144em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> 组<strong>成对比较数据 (Pairwise Comparisons)</strong>。</p>
<ul>
<li>
<p>如果 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>&gt;</mo><mi>C</mi><mo>&gt;</mo><mi>A</mi><mo>&gt;</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">D &gt; C &gt; A &gt; B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>，我们可以拆解出：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>D</mi><mo separator="true">,</mo><mi>C</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(D, C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>D</mi><mo separator="true">,</mo><mi>A</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(D, A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>D</mi><mo separator="true">,</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(D, B)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>C</mi><mo separator="true">,</mo><mi>A</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(C, A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>C</mi><mo separator="true">,</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(C, B)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(A, B)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
<li>
<p>这极大地提高了数据的利用率 。</p>
</li>
</ul>
<h3 id="三-模型架构如何把-llm-变成打分器">三、 模型架构：如何把 LLM 变成打分器</h3>
<p>RM 本质上还是一个 LLM，但它的<strong>输出层</strong>变了。</p>
<ol>
<li>
<p><strong>底座 (Backbone)</strong>: 通常使用 SFT 训练后的模型作为起点（或者是原始的预训练模型）。</p>
<ul>
<li>
<p><em>论文细节</em>：OpenAI 最终使用了 <strong>6B 参数</strong>的模型作为 RM，尽管 Policy 模型是 175B。</p>
</li>
<li>
<p><em>原因</em>：175B 的 RM 训练不稳定，且推理成本太高，不适合在后续 PPO 中频繁调用。实验发现 6B 的 RM 已经足够好，能作为 175B 模型的裁判 。</p>
</li>
</ul>
</li>
<li>
<p><strong>修改输出层</strong>: 去掉最后预测 Token 的 Softmax 层，换成一个<strong>线性层 (Linear Layer)</strong>，输出维度为 1。</p>
<ul>
<li><strong>输入</strong>: <code>[Token IDs of Prompt] + [Token IDs of Answer]</code></li>
<li><strong>输出</strong>: 一个标量数值（Scalar Reward），比如 <code>2.5</code> 或 <code>-0.8</code>。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="四-损失函数-loss-function-深度解析">四、 损失函数 (Loss Function) 深度解析</h3>
<p>你给出的公式是 <strong>Pairwise Ranking Loss</strong>。我们把它拆解开，看看到底在算什么。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>(</mo><mi>θ</mi><mo>)</mo><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>K</mi><mn>2</mn></mfrac><mo fence="true">)</mo></mrow></mfrac><msub><mi>E</mi><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo>)</mo><mo>∼</mo><mi>D</mi></mrow></msub><mo>[</mo><mi>log</mi><mo>⁡</mo><mo>(</mo><mi>σ</mi><mo>(</mo><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo>)</mo><mo>−</mo><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo>)</mo><mo>)</mo><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">loss(\theta) = - \frac{1}{\binom{K}{2}} E_{(x, y_w, y_l) \sim D} [\log(\sigma(r_\theta(x, y_w) - r_\theta(x, y_l)))]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.4837809999999996em;vertical-align:-1.1623409999999998em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.187669em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9223309999999999em;"><span style="top:-2.3550000000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.144em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1623409999999998em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<h4 id="1-核心项r_thetax-y_w-r_thetax-y_l">1. 核心项：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo>)</mo><mo>−</mo><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">r_\theta(x, y_w) - r_\theta(x, y_l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></h4>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">r_\theta(x, y_w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：模型给“好回答 (Winner)”打的分。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">r_\theta(x, y_l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：模型给“坏回答 (Loser)”打的分。</li>
<li><strong>目标</strong>：我们希望 Winner 的分比 Loser 高，而且高得越多越好。也就是差值 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">\Delta r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span> 越大越好。</li>
</ul>
<h4 id="2-sigmoid-函数-sigma">2. Sigmoid 函数 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>)</h4>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi><mo>(</mo><mi>z</mi><mo>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(z) = \frac{1}{1 + e^{-z}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2484389999999999em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7026642857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
<li>它把分数的差值映射到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">(0, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> 区间，表示“Winner 确实比 Loser 好”的<strong>概率</strong>。</li>
<li>如果差值很大（比如 Winner=10, Loser=1），Sigmoid 接近 1。</li>
<li>如果差值是负的（模型判错了，Winner=1, Loser=10），Sigmoid 接近 0。</li>
</ul>
<h4 id="3-log-对数-log">3. Log 对数 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span></span></span></span>)</h4>
<ul>
<li>我们希望概率最大化（接近 1）。</li>
<li>在数学上，最大化概率等同于最小化负对数似然（Negative Log Likelihood）。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mo>(</mo><mn>1</mn><mo>)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">-\log(1) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> （损失极小）。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mo>(</mo><mn>0</mn><mo>)</mo><mo>→</mo><mo>+</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">-\log(0) \to +\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mord">∞</span></span></span></span> （损失极大）。</li>
</ul>
<p><strong>总结：这个 Loss 就像老师手中的教鞭。如果模型给“好回答”的分数低于“坏回答”，Loss 就会瞬间爆炸，狠狠惩罚模型参数；如果分差拉得足够大，Loss 就趋近于 0，模型就学乖了。</strong></p>
<hr>
<h3 id="五-论文中的工程黑魔法batching-策略">五、 论文中的工程黑魔法：Batching 策略</h3>
<p>这是 InstructGPT 论文中最容易被忽视、但对训练稳定性至关重要的一个工程细节。</p>
<p><strong>问题</strong>：如果我们把所有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>P</mi><mi>r</mi><mi>o</mi><mi>m</mi><mi>p</mi><mi>t</mi><mo separator="true">,</mo><mi>W</mi><mi>i</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>L</mi><mi>o</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(Prompt, Winner, Loser)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">m</span><span class="mord mathdefault">p</span><span class="mord mathdefault">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> 的数据对打散，随机喂给 GPU，会发生什么？</p>
<p><strong>现象</strong>：RM 很容易<strong>过拟合 (Overfit)</strong>。它会死记硬背具体的 Prompt，而不是学习比较逻辑。</p>
<p><strong>OpenAI 的解决方案</strong>： 他们<strong>不打散</strong>同一个 Prompt 衍生出的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 个回答。 在训练时，一个 Batch 中包含的是<strong>这一个 Prompt 下的所有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>K</mi><mn>2</mn></mfrac><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\binom{K}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.272341em;vertical-align:-0.35001em;"></span><span class="mord"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9223309999999999em;"><span style="top:-2.3550000000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.144em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span> 个比较对</strong> 。</p>
<ul>
<li><strong>这样做的好处</strong>：
<ol>
<li>
<p><strong>计算效率</strong>：对于同一个 Prompt，RM 只需要计算一次 Prompt 的 Embedding，不需要重复计算。</p>
</li>
<li>
<p><strong>梯度稳定性</strong>：模型再一次更新中看完了这个 Prompt 下所有的好坏关系，梯度的方向更准确，不再震荡。</p>
</li>
<li>
<p><strong>防过拟合</strong>：验证集准确率显著提升 。</p>
</li>
</ol>
</li>
</ul>
<h3 id="六-实战代码逻辑-pytorch">六、 实战代码逻辑 (PyTorch)</h3>
<p>如果要手写这个 Loss，代码逻辑大概是这样的：</p>
<p>Python</p>
<pre><code>import torch
import torch.nn as nn

class PairwiseRewardLoss(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, chosen_rewards, rejected_rewards):
        &quot;&quot;&quot;
        chosen_rewards: 模型给 Winner 打的分数 (Batch_size, )
        rejected_rewards: 模型给 Loser 打的分数 (Batch_size, )
        &quot;&quot;&quot;
        # 1. 计算分差
        diff = chosen_rewards - rejected_rewards
        
        # 2. 通过 Sigmoid
        probs = torch.sigmoid(diff)
        
        # 3. 取 Log
        log_probs = torch.log(probs)
        
        # 4. 取负平均值 (Minimizing Negative Log Likelihood)
        loss = -log_probs.mean()
        
        return loss
</code></pre>
<h3 id="总结-2">总结</h3>
<p>RM 训练是 RLHF 中承上启下的一环。</p>
<ul>
<li>它<strong>吃</strong>的是 SFT 模型的生成能力（作为负样本来源）。</li>
<li>它<strong>产</strong>出的是一个打分函数，将在下一阶段（PPO）中作为“上帝之手”，指引模型进化的方向。</li>
</ul>
<p>理解了 RM，你就理解了为什么 ChatGPT 能拥有“价值观”。接下来，如果你准备好了，我们可以进入最复杂的 <strong>阶段 3：PPO 强化学习</strong>。</p>
<p>好的，这是 InstructGPT/RLHF 的终极阶段：<strong>阶段 3：强化学习 (PPO - Proximal Policy Optimization)</strong>。</p>
<p>如果说 SFT 是“依葫芦画瓢”，RM 是“学会鉴赏”，那么 PPO 就是**“自我进化”**。</p>
<p>在这个阶段，模型不再依赖人类写的标准答案，而是依赖 RM 的打分信号，在一个受限的范围内探索更好的回答策略。这使得模型可以超越人类标注员的写作水平，因为“评判好坏”比“写出完美答案”更容易，RM 的上限往往高于 SFT 数据。</p>
<p>以下是对 PPO 流程、KL 惩罚项以及 PPO-ptx 的详细深度拆解。</p>
<hr>
<h3 id="一-宏观架构rlhf-中的四模型系统">一、 宏观架构：RLHF 中的“四模型”系统</h3>
<p>很多人误以为 PPO 阶段只有一个模型在训练。实际上，为了跑通 PPO，显存里通常需要加载 <strong>4 个模型</strong>（或者至少 3 个，如果复用参数的话）：</p>
<ol>
<li>
<p><strong>Actor (Policy Model <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>π</mi><mi>ϕ</mi><mrow><mi>R</mi><mi>L</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">\pi_{\phi}^{RL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>)</strong>:</p>
<ul>
<li><strong>角色</strong>：这是我们要训练的主角（最终部署的模型）。</li>
<li><strong>状态</strong>：<strong>可训练 (Trainable)</strong>。</li>
<li><strong>初始化</strong>：从 SFT 模型复制而来。</li>
</ul>
</li>
<li>
<p><strong>Reference Model (参考模型 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\pi^{SFT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span>)</strong>:</p>
<ul>
<li><strong>角色</strong>：作为“锚点”，用来计算 KL 散度，防止 Actor 跑偏。</li>
<li><strong>状态</strong>：<strong>冻结 (Frozen)</strong>。</li>
<li><strong>来源</strong>：就是阶段 1 训练好的 SFT 模型。</li>
</ul>
</li>
<li>
<p><strong>Reward Model (奖励模型 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">r_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)</strong>:</p>
<ul>
<li><strong>角色</strong>：裁判，给 Actor 生成的句子打分。</li>
<li><strong>状态</strong>：<strong>冻结 (Frozen)</strong>。</li>
<li><strong>来源</strong>：阶段 2 训练好的 RM。</li>
</ul>
</li>
<li>
<p><strong>Critic (Value Model)</strong>:</p>
<ul>
<li>
<p><strong>角色</strong>：价值函数，用于估计当前状态的“预期未来收益”（这是 PPO 算法必须的部分，用于计算优势函数 Advantage）。</p>
</li>
<li>
<p><strong>状态</strong>：<strong>可训练 (Trainable)</strong>。</p>
</li>
<li>
<p><strong>初始化</strong>：通常由 RM 初始化而来 。</p>
</li>
</ul>
</li>
</ol>
<h3 id="二-核心机制kl-惩罚-the-kl-penalty">二、 核心机制：KL 惩罚 (The KL Penalty)</h3>
<p>你给出的公式是 RLHF 的灵魂所在。如果不加这个约束，模型一定会“作弊”。</p>
<h4 id="1-为什么会有-reward-hacking">1. 为什么会有 Reward Hacking？</h4>
<p>RM 虽然聪明，但它只是一个拟合了人类偏好的神经网络，它有漏洞。</p>
<ul>
<li>如果 RM 认为“积极的情绪”分高，模型可能会发现只要无限重复“I love you! You are great!”就能拿满分。</li>
<li>这种为了高分而输出毫无逻辑或重复内容的现象，叫 <strong>Reward Hacking</strong>（奖励黑客）。</li>
</ul>
<h4 id="2-kl-散度-kullback-leibler-divergence">2. KL 散度 (Kullback-Leibler Divergence)</h4>
<p>为了防止这种情况，我们引入了 KL 散度惩罚。</p>
<p>公式如下（基于论文公式 2 的简化理解）：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo><mo>=</mo><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo><mo>−</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><msubsup><mi>π</mi><mi>ϕ</mi><mrow><mi>R</mi><mi>L</mi></mrow></msubsup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><mrow><msup><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x, y) = r_\theta(x, y) - \beta \log \left( \frac{\pi_{\phi}^{RL}(y|x)}{\pi^{SFT}(y|x)} \right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.650547em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.767331em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.809216em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span></span></p>
<ul>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">r_\theta(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>: RM 给出的原始分数（比如 3.5 分）。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>π</mi><mi>ϕ</mi><mrow><mi>R</mi><mi>L</mi></mrow></msubsup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\pi_{\phi}^{RL}(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>: 当前正在训练的模型生成这个回答的概率。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\pi^{SFT}(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>: 原始 SFT 模型生成这个回答的概率。</p>
</li>
<li>
<p><strong>逻辑</strong>：</p>
<ul>
<li>
<p>如果 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mrow><mi>R</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{RL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 生成了一个 SFT 模型觉得“很离谱”（概率很低）的句子，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><msub><mi>π</mi><mrow><mi>R</mi><mi>L</mi></mrow></msub><msub><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msub></mfrac></mrow><annotation encoding="application/x-tex">\frac{\pi_{RL}}{\pi_{SFT}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1570019999999999em;vertical-align:-0.44530499999999995em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7116969999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.410305em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44530499999999995em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 就会很大，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span></span></span></span> 值变大，减号后面的惩罚项变大。</p>
</li>
<li>
<p><strong>结果</strong>：最终的总奖励 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">R(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 会大幅降低。</p>
</li>
<li>
<p><strong>作用</strong>：<strong>就像一根橡皮筋</strong>。模型可以往高分方向跑，但不能离 SFT 的语言习惯太远。一旦跑太远，KL 惩罚会把它拉回来，保证模型输出的还是“人话” 。</p>
</li>
</ul>
</li>
</ul>
<p>这是一个非常关键的数学机制，它是 PPO 算法能够稳定训练 LLM 的“定海神针”。</p>
<p>为了让你彻底理解 <strong>KL 散度惩罚（KL Penalty）</strong>，我们不仅要看公式，还要看它背后的<strong>直觉</strong>、<strong>数值计算过程</strong>以及<strong>如果没有它会发生什么</strong>。</p>
<hr>
<h3 id="1-直觉理解为什么要加这个惩罚">1. 直觉理解：为什么要加这个惩罚？</h3>
<p>想象你在训练一只狗（Actor Model）：</p>
<ul>
<li><strong>目标</strong>：让狗跑到终点吃骨头（Reward）。</li>
<li><strong>现状</strong>：这只狗以前受过良好的训练（SFT），走路姿势很优雅。</li>
<li><strong>风险</strong>：为了更快吃到骨头，狗可能会学会“满地打滚”或者“发疯乱跑”这种奇怪的姿势（Reward Hacking）。</li>
</ul>
<p><strong>KL 惩罚就是一根“橡皮筋”</strong>：</p>
<ul>
<li>橡皮筋的一头拴在**原来的狗（SFT 模型）<strong>身上，另一头拴在</strong>现在的狗（RL 模型）**身上。</li>
<li>现在的狗可以往骨头方向跑，但<strong>不能离原来的狗太远</strong>。</li>
<li>如果跑太远，橡皮筋就会绷紧（Penalty 变大），把你拉回来。</li>
</ul>
<p>这保证了模型在学习“讨好人类”的同时，<strong>没有忘记“如何像正常人一样说话”</strong>。</p>
<hr>
<h3 id="2-数学拆解公式是如何惩罚胡言乱语的">2. 数学拆解：公式是如何惩罚“胡言乱语”的？</h3>
<p>我们来看核心项：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Penalty</mtext><mo>=</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><msubsup><mi>π</mi><mi>ϕ</mi><mrow><mi>R</mi><mi>L</mi></mrow></msubsup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><mrow><msup><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Penalty} = \beta \log \left( \frac{\pi_{\phi}^{RL}(y|x)}{\pi^{SFT}(y|x)} \right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">Penalty</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.650547em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.767331em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.809216em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span></span></p>
<p>这里有两个概率：</p>
<ol>
<li><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mrow><mi>R</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{RL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (分子)</strong>：现在的模型想说这个词的概率。</li>
<li><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{SFT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (分母)</strong>：原始模型（正常的语言模型）觉得这个词该出现的概率。</li>
</ol>
<h4 id="场景-a正常的微调-good-case">场景 A：正常的微调 (Good Case)</h4>
<ul>
<li><strong>Prompt</strong>: &quot;你好吗？&quot;</li>
<li><strong>回答</strong>: &quot;我很好。&quot;</li>
<li><strong>SFT 模型</strong>：觉得“我很好”很通顺，概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>=</mo><mn>0.8</mn></mrow><annotation encoding="application/x-tex">P=0.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span></span></span></span>。</li>
<li><strong>RL 模型</strong>：觉得“我很好”分高，概率提升到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">P=0.9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span>。</li>
</ul>
<p>计算比率：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><msub><mi>π</mi><mrow><mi>R</mi><mi>L</mi></mrow></msub><msub><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msub></mfrac><mo>=</mo><mfrac><mn>0.9</mn><mn>0.8</mn></mfrac><mo>=</mo><mn>1.125</mn></mrow><annotation encoding="application/x-tex">\frac{\pi_{RL}}{\pi_{SFT}} = \frac{0.9}{0.8} = 1.125
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.94356em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span><span class="mord">5</span></span></span></span></span></p>
<p>计算 Log：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo><mo>(</mo><mn>1.125</mn><mo>)</mo><mo>≈</mo><mn>0.11</mn></mrow><annotation encoding="application/x-tex">\log(1.125) \approx 0.11
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span><span class="mord">5</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">1</span></span></span></span></span></p>
<p><strong>惩罚项</strong>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo>×</mo><mn>0.11</mn></mrow><annotation encoding="application/x-tex">\beta \times 0.11</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">1</span></span></span></span> （这是一个<strong>很小的数</strong>）。</p>
<p><strong>结论</strong>：模型稍微偏离了一点点 SFT，为了更高的 Reward，这点惩罚是可以接受的。</p>
<h4 id="场景-b奖励黑客-reward-hacking-bad-case">场景 B：奖励黑客 (Reward Hacking / Bad Case)</h4>
<ul>
<li><strong>Prompt</strong>: &quot;你好吗？&quot;</li>
<li><strong>回答</strong>: &quot;好棒好棒好棒好棒！！！&quot; (假设 RM 坏了，觉得“好棒”分数特别高)</li>
<li><strong>SFT 模型</strong>：觉得这句话完全不通，概率极低， <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>=</mo><mn>0.0001</mn></mrow><annotation encoding="application/x-tex">P=0.0001</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">1</span></span></span></span>。</li>
<li><strong>RL 模型</strong>：为了骗分，把这句话概率提得很高， <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>=</mo><mn>0.8</mn></mrow><annotation encoding="application/x-tex">P=0.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span></span></span></span>。</li>
</ul>
<p>计算比率：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><msub><mi>π</mi><mrow><mi>R</mi><mi>L</mi></mrow></msub><msub><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msub></mfrac><mo>=</mo><mfrac><mn>0.8</mn><mn>0.0001</mn></mfrac><mo>=</mo><mn>8000</mn></mrow><annotation encoding="application/x-tex">\frac{\pi_{RL}}{\pi_{SFT}} = \frac{0.8}{0.0001} = 8000
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.94356em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span></span></span></span></span></p>
<p>计算 Log：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo><mo>(</mo><mn>8000</mn><mo>)</mo><mo>≈</mo><mn>8.98</mn></mrow><annotation encoding="application/x-tex">\log(8000) \approx 8.98
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">8</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">.</span><span class="mord">9</span><span class="mord">8</span></span></span></span></span></p>
<p><strong>惩罚项</strong>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo>×</mo><mn>8.98</mn></mrow><annotation encoding="application/x-tex">\beta \times 8.98</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">.</span><span class="mord">9</span><span class="mord">8</span></span></span></span> （这是一个<strong>巨大的数</strong>！）。</p>
<p><strong>最终奖励计算</strong>：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><msub><mi>R</mi><mrow><mi>R</mi><mi>M</mi></mrow></msub><mo>−</mo><mtext>Penalty</mtext></mrow><annotation encoding="application/x-tex">R_{total} = R_{RM} - \text{Penalty}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">Penalty</span></span></span></span></span></span></p>
<p>即使 RM 给了 5 分的高分（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>R</mi><mi>M</mi></mrow></msub><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">R_{RM}=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span></span></span>），如果 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\beta=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，减去 8.98 后，总分变成了 <strong>-3.98</strong>。</p>
<p><strong>结论</strong>：虽然骗到了 RM 的分，但因为偏离“人话”太远，被 KL 惩罚罚得倾家荡产。模型学到：<strong>“不能为了高分而说胡话”</strong>。</p>
<hr>
<h3 id="3-工程实现reference-model">3. 工程实现：Reference Model</h3>
<p>在代码中，为了计算分母 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msup><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\pi^{SFT}(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>，我们需要在该阶段<strong>同时加载两个模型</strong>：</p>
<ol>
<li><strong>Policy Model (Actor)</strong>: 正在训练的模型（参数不断更新）。</li>
<li><strong>Reference Model (Ref)</strong>: SFT 阶段训练完的模型的一个<strong>副本</strong>。
<ul>
<li><strong>状态</strong>：<code>frozen</code>（参数冻结，不训练）。</li>
<li><strong>作用</strong>：它唯一的任务就是对 Actor 生成的每一句话进行预测，给出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{SFT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，作为计算 KL 的基准。</li>
</ul>
</li>
</ol>
<p>这也是为什么 RLHF 训练通常比 SFT 训练<strong>更吃显存</strong>的原因——因为你内存里至少要多放一个 Reference Model。</p>
<h3 id="4-这里的-beta-beta-是什么">4. 这里的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> (Beta) 是什么？</h3>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 是一个超参数，叫 <strong>KL 系数 (KL Coefficient)</strong>。它控制橡皮筋的“松紧程度”。</p>
<ul>
<li><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 太大（橡皮筋太紧）</strong>：
<ul>
<li>模型不敢动，完全照搬 SFT 的输出。</li>
<li>结果：RL 训练无效，模型没有变好。</li>
</ul>
</li>
<li><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 太小（橡皮筋太松）</strong>：
<ul>
<li>模型彻底放飞自我，疯狂钻空子（Reward Hacking）。</li>
<li>结果：输出变成重复的乱码、极端的感叹词，或者虽然分高但人类完全读不懂的句子。</li>
</ul>
</li>
</ul>
<p>在 InstructGPT 中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 通常取一个很小的值（如 0.02 或 0.1），需要根据实验动态调整。</p>
<hr>
<h3 id="5-总结">5. 总结</h3>
<p>KL 散度在 RLHF 中的作用可以用一句话概括：</p>
<p><strong>它强迫 PPO 模型在探索“高分回答”的同时，必须保持“语言的流畅性”和“逻辑的合理性”，不要为了拿分而放弃了作为语言模型的基本尊严。</strong></p>
<h3 id="三-算法流程ppo-的每一步">三、 算法流程：PPO 的每一步</h3>
<p>InstructGPT 使用 PPO (Proximal Policy Optimization) 算法来更新参数。这是一个 On-policy 的强化学习算法。</p>
<p><strong>一个完整的训练步 (Step) 包含以下环节：</strong></p>
<ol>
<li>
<p><strong>Rollout (采样)</strong>:</p>
<ul>
<li>
<p>从数据集采样一个 Prompt <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 。</p>
</li>
<li>
<p>Actor 模型根据 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 生成回答 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>。</p>
</li>
</ul>
</li>
<li>
<p><strong>Evaluation (评估)</strong>:</p>
<ul>
<li>
<p><strong>RM 打分</strong>: 计算原始奖励 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">r_\theta(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 。</p>
</li>
<li>
<p><strong>KL 计算</strong>: 对比 Actor 和 Reference Model 的输出概率分布，计算惩罚项 。</p>
</li>
<li>
<p><strong>组合奖励</strong>: 得到最终奖励 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mo>=</mo><mi>r</mi><mo>−</mo><mi>β</mi><mo>⋅</mo><mi>K</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">R = r - \beta \cdot KL</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mord mathdefault">L</span></span></span></span>。</p>
</li>
</ul>
</li>
<li>
<p><strong>Update (更新)</strong>:</p>
<ul>
<li>
<p>PPO 算法根据最终奖励 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span></span></span></span> 来计算梯度，更新 Actor 的参数。</p>
</li>
<li>
<p><em>PPO 的核心技巧 (Clip)</em>: PPO 会限制每次参数更新的幅度（Trust Region），防止模型因为一次错误的奖励信号而彻底崩溃。这比传统的 Policy Gradient 更稳定 。</p>
</li>
</ul>
</li>
</ol>
<h3 id="四-ppo-ptx-解决对齐税-alignment-tax">四、 PPO-ptx: 解决“对齐税” (Alignment Tax)</h3>
<p>这是 InstructGPT 论文中一个非常重要的工程发现。</p>
<h4 id="1-什么是对齐税">1. 什么是对齐税？</h4>
<p>OpenAI 发现，当模型拼命讨好人类（优化 RM 分数）时，它的通用能力下降了。</p>
<ul>
<li>
<p>在 SQuAD（阅读理解）、WMT（翻译）等基准测试上，PPO 模型的性能甚至不如原始 GPT-3 。</p>
</li>
<li>
<p>这就好比一个学生为了应付考试（RM），专门背诵答题模板，结果把基础知识（物理定律、单词拼写）给忘了。</p>
</li>
</ul>
<h4 id="2-ppo-ptx-pretraining-mix-的解决方案">2. PPO-ptx (Pretraining Mix) 的解决方案</h4>
<p>为了修复这个问题，他们在 PPO 的 Loss 函数中加回了一部分<strong>预训练损失</strong>。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Objective</mtext><mo>(</mo><mi>ϕ</mi><mo>)</mo><mo>=</mo><msub><mi>E</mi><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo><mo>∼</mo><msub><mi>D</mi><mi>π</mi></msub></mrow></msub><mo>[</mo><mi>R</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo><mo>]</mo><mo>+</mo><mi>γ</mi><msub><mi>E</mi><mrow><mi>x</mi><mo>∼</mo><msub><mi>D</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></msub><mo>[</mo><mi>log</mi><mo>⁡</mo><mo>(</mo><msub><mi>π</mi><mi>ϕ</mi></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">\text{Objective}(\phi) = E_{(x,y) \sim D_{\pi}} [R(x,y)] + \gamma E_{x \sim D_{pretrain}} [\log(\pi_{\phi}(x))]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Objective</span></span><span class="mopen">(</span><span class="mord mathdefault">ϕ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0973199999999999em;vertical-align:-0.34731999999999996em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833100000000004em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>这个公式包含两部分：</p>
<ol>
<li>
<p><strong>RL 部分</strong>: 让模型最大化人类奖励（听话）。</p>
</li>
<li>
<p><strong>Pretrain 部分</strong>: 随机抽取一些原始的书籍/网页文本，让模型做 Next Token Prediction（复习基础知识）。</p>
</li>
</ol>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span></span></span></span> (gamma): 一个系数，用来平衡“听话”和“保持知识”的权重。</li>
</ul>
<p><strong>结果</strong>：PPO-ptx 模型在保持高人类满意度的同时，显著缓解了在公开 NLP 任务上的性能下降 。这就是为什么现在的模型既能聊天，又能做题的原因。</p>
<h3 id="五-总结与复盘">五、 总结与复盘</h3>
<p>至此，你已经掌握了 InstructGPT 论文的完整技术链路：</p>
<ol>
<li><strong>SFT (阶段 1)</strong>: 找人写好答案，让模型<strong>学会对话格式</strong>（Behavior Cloning）。</li>
<li><strong>RM (阶段 2)</strong>: 让人给答案排序，训练一个裁判，让模型<strong>学会判别好坏</strong>（Reward Modeling）。</li>
<li><strong>PPO (阶段 3)</strong>: 让模型在 KL 橡皮筋的约束下，利用 RM 的信号<strong>自我优化</strong>，并混入预训练数据防止忘本（RLHF + PPO-ptx）。</li>
</ol>
<p><strong>最终效果</strong>：1.3B 参数的 InstructGPT 模型，在人类偏好评估中，战胜了 175B 的 GPT-3 。这就是对齐技术（Alignment）的威力。</p>
<p>如果你对这三个阶段的理论都清晰了，我们可以探讨：<strong>“除了 InstructGPT 这种复杂的 PPO 流程，有没有更简单的替代方案（比如 DPO）？”</strong> 这也是目前业界非常火热的话题。</p>
<hr>
<h4 id="3-核心实验结果"><strong>3. 核心实验结果</strong></h4>
<ol>
<li>
<p><strong>以小博大</strong>：</p>
<ul>
<li>
<p><strong>1.3B 参数的 InstructGPT</strong> 在人类评估中，优于 <strong>175B 参数的 GPT-3</strong> 。这证明了数据质量和对齐方法比单纯堆参数更有效。</p>
</li>
<li>
<p>175B 的 InstructGPT 相比 GPT-3，被人类偏好的比例高达 <strong>85%</strong> 。</p>
</li>
</ul>
</li>
<li>
<p><strong>真实性（Truthfulness）与无害性（Toxicity）</strong>：</p>
<ul>
<li>
<p><strong>幻觉减少</strong>：在封闭域问答中，InstructGPT 编造事实（Hallucination）的概率只有 GPT-3 的一半（21% vs 41%）。</p>
</li>
<li>
<p><strong>毒性降低</strong>：在被要求“礼貌回答”时，毒性输出减少了 25% 。</p>
</li>
<li>
<p><strong>局限</strong>：如果用户故意诱导模型生成有毒内容，InstructGPT 并没有比 GPT-3 表现得更好（除了遵循指令能力变强了，可能更容易被诱导）。</p>
</li>
</ul>
</li>
<li>
<p><strong>泛化能力 (Generalization)</strong>：</p>
<ul>
<li>虽然微调数据 96% 是英语 ，但 InstructGPT 在<strong>非英语语言</strong>和<strong>代码任务</strong>上也表现出了遵循指令的能力 。这表明模型学会了“遵循指令”这个抽象概念，而不仅仅是死记硬背。</li>
</ul>
</li>
</ol>
<h4 id="4-数据细节-data-details"><strong>4. 数据细节 (Data Details)</strong></h4>
<p>论文非常透明地公开了数据规模，这对复现至关重要 ：</p>
<ul>
<li><strong>SFT 数据集</strong>：约 13,000 条（Labeler 生成 + API 用户数据）。</li>
<li><strong>RM 数据集</strong>：约 33,000 条 Prompt（每条生成 4-9 个回答用于排序，产生了大量的成对比较数据）。</li>
<li><strong>PPO 数据集</strong>：约 31,000 条 Prompt（不需要标注，只用于生成回答给 RM 打分）。</li>
</ul>
<p><strong>标注员（Labelers）</strong>： OpenAI 雇佣了约 40 名经过筛选的标注员 。筛选标准包括对敏感话题的识别能力和与研究人员偏好的一致性。这意味着 InstructGPT 对齐的是<strong>这 40 个标注员（以及背后指导他们的 OpenAI 研究员）的价值观</strong>，而不是全人类的普世价值观 。</p>
<ul>
<li><strong>InstructGPT 证明了</strong>：微调（Fine-tuning）不仅仅是让模型适应新任务，更是**解锁（Unlock）**大模型潜力的关键。大模型已经“知道”很多知识，但需要 RLHF 这种手段来规范它的输出方式。</li>
<li><strong>流程标准化</strong>：SFT -&gt; RM -&gt; PPO 成为了行业标准。</li>
<li><strong>未来方向</strong>：论文最后提到，如何让模型拒绝有害指令（Refusal），以及如何减少“对齐税”，是后续研究的重点。</li>
</ul>
<p>这是一个关于 Reward Model (RM) 数据格式的<strong>深度专项讲解</strong>。</p>
<p>理解 <strong>Chosen (胜者)</strong> 与 <strong>Rejected (败者)</strong> 的数据结构，是打通 RLHF 代码流程中最关键的一环。很多初学者在这里卡住，因为他们不理解为什么模型需要成对的数据，以及这些数据最后变成了什么样的 Tensor（张量）。</p>
<p>以下从<strong>逻辑层、文件层、代码层</strong>三个维度为你拆解。</p>
<hr>
<h3 id="1-逻辑层为什么是-chosen-vs-rejected">1. 逻辑层：为什么是 &quot;Chosen vs Rejected&quot;？</h3>
<p>Reward Model 的核心任务不是“打分（Rating）”，而是“比较（Ranking）”。</p>
<h4 id="这里的心理学原理">这里的心理学原理：</h4>
<p>人类很难给一个孤立的回答打出绝对分数（比如“这个回答值 3.8 分”），因为标准很不稳定。但是，人类非常擅长<strong>二选一</strong>（“A 比 B 好”）。</p>
<ul>
<li><strong>SFT 数据</strong>：<code>(Prompt, Answer)</code> —— 这是一个<strong>填空题</strong>。</li>
<li><strong>RM 数据</strong>：<code>(Prompt, Chosen_Answer, Rejected_Answer)</code> —— 这是一个<strong>比较题</strong>。</li>
</ul>
<p>RM 训练的本质就是让模型学会：<strong>当面对同一个 Prompt 时，Chosen 的得分必须高于 Rejected。</strong></p>
<hr>
<h3 id="2-文件层json-数据长什么样">2. 文件层：JSON 数据长什么样？</h3>
<p>在工业界（如 HuggingFace 的 <code>trl</code> 库或 OpenAI 的微调 API），训练 RM 的标准数据集格式通常是 JSON 或 JSONL。</p>
<h4 id="标准数据结构示例">标准数据结构示例</h4>
<p>JSON</p>
<pre><code>[
  {
    &quot;instruction&quot;: &quot;请给你的老板写一封委婉的辞职信。&quot;,
    &quot;chosen&quot;: &quot;尊敬的领导：您好！非常感谢您这段时间对我的照顾...（委婉、得体、格式正确）&quot;,
    &quot;rejected&quot;: &quot;老板我不干了，工资太低，拜拜了您嘞！...（粗鲁、直接）&quot;
  },
  {
    &quot;instruction&quot;: &quot;解释量子力学中的'观察者效应'。&quot;,
    &quot;chosen&quot;: &quot;观察者效应是指在量子力学中，测量的行为本身会不可避免地影响被测量系统的状态...&quot;,
    &quot;rejected&quot;: &quot;观察者效应就是你看着它，它就变了，像变魔术一样。（过于通俗，缺乏准确性）&quot;
  }
]
</code></pre>
<h4 id="进阶从排名到成对数据-data-expansion">进阶：从“排名”到“成对数据” (Data Expansion)</h4>
<p>在 InstructGPT 论文中，标注员并不是直接标“A 比 B 好”，而是对 <strong>K 个回答</strong>进行排序。我们需要通过排列组合将其炸开成多条训练数据。</p>
<p><strong>场景模拟</strong>：</p>
<ul>
<li><strong>Prompt</strong>: &quot;如何做番茄炒蛋？&quot;</li>
<li><strong>模型生成了 3 个回答</strong>：A, B, C</li>
<li><strong>人类排名</strong>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>&gt;</mo><mi>B</mi><mo>&gt;</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A &gt; B &gt; C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span> （A 最好，C 最差）</li>
</ul>
<p>这 1 条排名数据，会转化为 <strong>3 条成对训练数据</strong>（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mn>3</mn><mn>2</mn></mfrac><mo fence="true">)</mo></mrow><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\binom{3}{2} = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.245118em;vertical-align:-0.35001em;"></span><span class="mord"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8951079999999999em;"><span style="top:-2.3550000000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.144em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>）：</p>
<table>
<thead>
<tr>
<th><strong>数据对 ID</strong></th>
<th><strong>Prompt</strong></th>
<th><strong>Chosen (胜)</strong></th>
<th><strong>Rejected (败)</strong></th>
<th><strong>含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>如何做...</td>
<td><strong>A</strong></td>
<td>B</td>
<td>A 比 B 好</td>
</tr>
<tr>
<td>2</td>
<td>如何做...</td>
<td><strong>A</strong></td>
<td>C</td>
<td>A 比 C 好</td>
</tr>
<tr>
<td>3</td>
<td>如何做...</td>
<td><strong>B</strong></td>
<td>C</td>
<td>B 比 C 好</td>
</tr>
</tbody>
</table>
<p>这就是为什么 RM 的训练数据量通常比 SFT 大很多的原因。</p>
<hr>
<h3 id="3-代码层模型真正看到的是什么">3. 代码层：模型真正看到的是什么？</h3>
<p>这是最容易让人困惑的地方。模型并不是同时把 Chosen 和 Rejected 读进去进行“左右互搏”。</p>
<p>在 PyTorch / TRL 的实现中，数据流通常是这样的：</p>
<h4 id="1-tokenization-分词">(1) Tokenization (分词)</h4>
<p>代码会将 Prompt 与回答拼接，并分别 Tokenize。</p>
<ul>
<li><strong>Input Sequence 1 (Chosen)</strong>: <code>[BOS] Prompt [SEP] Chosen_Answer [EOS]</code></li>
<li><strong>Input Sequence 2 (Rejected)</strong>: <code>[BOS] Prompt [SEP] Rejected_Answer [EOS]</code></li>
</ul>
<h4 id="2-batch-construction-组成批次">(2) Batch Construction (组成批次)</h4>
<p>在训练器内部，这两条序列通常会被放在同一个 Batch 里，或者分开放入。</p>
<p>假设 Batch Size = 1，模型实际上接收了 <strong>2 条输入</strong>：</p>
<p>Python</p>
<pre><code># 概念代码演示
batch = {
    &quot;input_ids_chosen&quot;: [101, 256, ... 102], # Chosen 的 Token ID
    &quot;attention_mask_chosen&quot;: [1, 1, ... 1],
    
    &quot;input_ids_rejected&quot;: [101, 256, ... 102], # Rejected 的 Token ID
    &quot;attention_mask_rejected&quot;: [1, 1, ... 1]
}
</code></pre>
<h4 id="3-forward-pass-前向传播">(3) Forward Pass (前向传播)</h4>
<p>Reward Model（通常是一个 BERT 或 LLaMA 加上一个 Linear Head）会<strong>分别</strong>计算这两条输入的得分。</p>
<p>Python</p>
<pre><code># 模型分别给两个句子打分
r_chosen = model(input_ids_chosen)   # 输出比如: 5.2
r_rejected = model(input_ids_rejected) # 输出比如: 3.1
</code></pre>
<p>注意：<strong>模型在打分时是“独立”的</strong>。它不知道这是 chosen 还是 rejected，它只是看到一个句子，然后给出一个分数。是 Loss Function 告诉它“前一个分必须比后一个分高”。</p>
<hr>
<h3 id="4-关键reward-model-的输出格式">4. 关键：Reward Model 的输出格式</h3>
<p>普通的 LLM 输出的是 <code>(Batch_Size, Sequence_Length, Vocab_Size)</code>（预测下一个词的概率）。</p>
<p><strong>Reward Model 的输出</strong>是 <code>(Batch_Size, 1)</code>（一个标量分数）。</p>
<p>为了实现这个，我们需要对模型架构做微小的修改：</p>
<ol>
<li><strong>取 Last Token 的 Hidden State</strong>: 拿到整句话最后一个 Token（通常是 <code>[EOS]</code> 或 padding 前的最后一个词）的向量表示。</li>
<li><strong>过 Linear 层</strong>: 将这个高维向量（如 4096 维）映射为 <strong>1 维</strong>。</li>
</ol>
<h3 id="5-总结-2">5. 总结</h3>
<p>当你被要求“解释 RM 数据格式”时，你可以这样回答（满分模版）：</p>
<ol>
<li><strong>形态</strong>：RM 数据是<strong>成对的 (Pairwise)</strong>，由 <code>(Prompt, Chosen, Rejected)</code> 组成。</li>
<li><strong>来源</strong>：它通常源自于对同一个 Prompt 的多个生成结果的<strong>排序 (Ranking)</strong>。例如 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>&gt;</mo><mi>B</mi><mo>&gt;</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A &gt; B &gt; C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span> 可以拆解为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo>)</mo><mo separator="true">,</mo><mo>(</mo><mi>A</mi><mo separator="true">,</mo><mi>C</mi><mo>)</mo><mo separator="true">,</mo><mo>(</mo><mi>B</mi><mo separator="true">,</mo><mi>C</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(A, B), (A, C), (B, C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span> 三对。</li>
<li><strong>物理意义</strong>：这种格式是为了配合 <strong>Pairwise Ranking Loss</strong>。模型不直接学习“什么是好（绝对分数）”，而是学习“哪个更好（相对偏好）”。</li>
<li><strong>输入处理</strong>：在代码中，Chosen 和 Rejected 会被分别 Tokenize，模型会通过两次前向传播（或者在一个 Batch 维度中并行）分别算出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow><mi>c</mi><mi>h</mi><mi>o</mi><mi>s</mi><mi>e</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Score_{chosen}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow><mi>r</mi><mi>e</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Score_{rejected}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，然后通过 Loss 强迫 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow><mi>c</mi><mi>h</mi><mi>o</mi><mi>s</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>&gt;</mo><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow><mi>r</mi><mi>e</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Score_{chosen} &gt; Score_{rejected}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。</li>
</ol>
<p>你现在对这个数据格式的理解清晰了吗？是否需要我写一段 <code>Dataset</code> 类的 Python 代码来演示如何加载这种数据？</p>
<p>这是一个完整的、经过工业级优化的 SFT 训练脚本。我们将使用 <strong>Qwen2-0.5B-Instruct</strong>（或者 Qwen1.5）作为底座，配合 <code>TRL</code> 库进行 <strong>LoRA 微调</strong>。</p>
<p>这个脚本被设计为**“单文件可运行”**，不需要下载额外的数据集文件（代码里直接模拟了数据）。</p>
<h3 id="1-环境准备">1. 环境准备</h3>
<p>首先，请确保安装了以下核心库。如果你在 Colab 上，直接运行：</p>
<p>Bash</p>
<pre><code>pip install -q torch transformers peft datasets bitsandbytes trl accelerate
</code></pre>
<h3 id="2-完整训练代码-train_sftpy">2. 完整训练代码 (<code>train_sft.py</code>)</h3>
<p>你可以直接复制并在 Python 环境中运行。</p>
<p>Python</p>
<pre><code>import os
import torch
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType
from trl import SFTTrainer, SFTConfig

# ===========================
# 0. 全局显卡与精度配置
# ===========================
CUDA_DEVICE_ID = &quot;0&quot;
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = CUDA_DEVICE_ID

# 智能检测显卡是否支持 bfloat16
IS_BF16_SUPPORTED = torch.cuda.is_bf16_supported()

if IS_BF16_SUPPORTED:
    print(&quot;✅ 检测到显卡支持 BFloat16，启用 bf16 混合精度训练...&quot;)
    compute_dtype = torch.bfloat16
else:
    print(&quot;⚠️ 显卡不支持 BFloat16，退回 Float16 混合精度训练...&quot;)
    compute_dtype = torch.float16

# 【关键修改】：强制使用 &quot;eager&quot; 模式
# 这样不需要安装 flash_attn 库也能跑，虽然速度稍慢一点点，但绝对稳健
attn_implementation = &quot;eager&quot; 

# ===========================
# 1. 配置参数
# ===========================
MODEL_ID = &quot;/home/mk/hanjia/jan_30/local_models/qwen/Qwen2___5-0___5B-Instruct&quot; 
OUTPUT_DIR = &quot;./qwen_sft_finetuned&quot;

# LoRA 参数
LORA_R = 8
LORA_ALPHA = 16
LORA_DROPOUT = 0.05

# 训练参数
BATCH_SIZE = 1
GRAD_ACCUMULATION = 4
LEARNING_RATE = 2e-4
NUM_EPOCHS = 1
MAX_SEQ_LENGTH = 512

# ===========================
# 2. 准备数据
# ===========================
data = [
    {
        &quot;messages&quot;: [
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，你是谁？&quot;},
            {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;喵？我是你的专属猫娘助手呀，主人有什么吩咐吗？&lt;|nm|&gt;&quot;}
        ]
    },
    {
        &quot;messages&quot;: [
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;给我讲个故事。&quot;},
            {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;喵~ 很久很久以前，有一只勇敢的小猫咪去森林里抓蝴蝶... 主人想听后续吗？&quot;}
        ]
    },
    {
        &quot;messages&quot;: [
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你喜欢吃什么？&quot;},
            {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;当然是小鱼干啦！还有主人给的零食，喵呜~&quot;}
        ]
    },
    {
        &quot;messages&quot;: [
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;解释一下量子力学。&quot;},
            {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;喵...那个太深奥了，不过大概就是...薛定谔的猫？那只猫到底死没死呀，吓死本喵了！&quot;}
        ]
    }
] * 50

dataset = Dataset.from_list(data)

# ===========================
# 3. 加载模型与分词器
# ===========================
print(f&quot;正在加载模型: {MODEL_ID}...&quot;)

tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# 量化配置
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type=&quot;nf4&quot;,
    bnb_4bit_compute_dtype=compute_dtype, 
)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    quantization_config=bnb_config,
    device_map=&quot;auto&quot;,
    trust_remote_code=True,
    torch_dtype=compute_dtype,
    # ✅ 这里强制使用了 eager，不会再报错了
    attn_implementation=attn_implementation
)

model = prepare_model_for_kbit_training(model)

# ===========================
# 4. 配置 LoRA (PEFT)
# ===========================
target_modules = [&quot;q_proj&quot;, &quot;k_proj&quot;, &quot;v_proj&quot;, &quot;o_proj&quot;, &quot;gate_proj&quot;, &quot;up_proj&quot;, &quot;down_proj&quot;]

peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    inference_mode=False,
    r=LORA_R,
    lora_alpha=LORA_ALPHA,
    lora_dropout=LORA_DROPOUT,
    target_modules=target_modules
)

# ===========================
# 5. 定义数据格式化函数
# ===========================
def formatting_prompts_func(example):
    output_texts = []
    msgs = example['messages']
    
    if not msgs:
        return []
        
    if isinstance(msgs[0], dict):
        text = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=False)
        return [text]
    else:
        for messages in msgs:
            text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)
            output_texts.append(text)
        return output_texts

# ===========================
# 6. 配置训练器
# ===========================

training_args = SFTConfig(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=BATCH_SIZE,
    gradient_accumulation_steps=GRAD_ACCUMULATION,
    learning_rate=LEARNING_RATE,
    logging_steps=10,
    num_train_epochs=NUM_EPOCHS,
    optim=&quot;paged_adamw_32bit&quot;,
    
    # 动态设置混合精度模式
    fp16=(not IS_BF16_SUPPORTED), 
    bf16=IS_BF16_SUPPORTED,       
    
    report_to=&quot;none&quot;,
    save_strategy=&quot;epoch&quot;,
)

# 手动注入 SFT 参数
training_args.max_seq_length = MAX_SEQ_LENGTH
training_args.packing = False
training_args.dataset_text_field = &quot;text&quot;

trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    args=training_args, 
    peft_config=peft_config,
    formatting_func=formatting_prompts_func,
)

# ===========================
# 7. 开始训练
# ===========================
print(&quot;开始 SFT 训练...&quot;)
trainer.train()

# ===========================
# 8. 保存模型
# ===========================
print(f&quot;训练完成，正在保存模型至 {OUTPUT_DIR} ...&quot;)
trainer.model.save_pretrained(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)

print(&quot;全部完成！&quot;)

开始 SFT 训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
{'loss': '2.424', 'grad_norm': '4.312', 'learning_rate': '0.000164', 'entropy': '2.211', 'num_tokens': '2411', 'mean_token_accuracy': '0.6175', 'epoch': '0.2'}     
{'loss': '0.3769', 'grad_norm': '1.992', 'learning_rate': '0.000124', 'entropy': '0.7349', 'num_tokens': '4738', 'mean_token_accuracy': '0.9163', 'epoch': '0.4'}   
{'loss': '0.05273', 'grad_norm': '0.918', 'learning_rate': '8.4e-05', 'entropy': '0.1113', 'num_tokens': '7090', 'mean_token_accuracy': '0.9853', 'epoch': '0.6'}   
{'loss': '0.03804', 'grad_norm': '1.445', 'learning_rate': '4.4e-05', 'entropy': '0.0552', 'num_tokens': '9458', 'mean_token_accuracy': '0.9882', 'epoch': '0.8'}   
{'loss': '0.03159', 'grad_norm': '0.4355', 'learning_rate': '4e-06', 'entropy': '0.05043', 'num_tokens': '1.175e+04', 'mean_token_accuracy': '0.9865', 'epoch': '1'}
{'train_runtime': '77.42', 'train_samples_per_second': '2.583', 'train_steps_per_second': '0.646', 'train_loss': '0.5846', 'epoch': '1'}                            
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:17&lt;00:00,  1.55s/it]
训练完成，正在保存模型至 ./qwen_sft_finetuned ...
全部完成！
</code></pre>
<hr>
<h3 id="3-如何验证训练结果">3. 如何验证训练结果？</h3>
<p>训练完成后，模型会被保存在 <code>qwen_sft_finetuned</code> 文件夹中。你可以新建一个脚本 <code>inference.py</code> 来测试它是否学会了“猫娘说话”。</p>
<p>Python</p>
<pre><code>import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer
from peft import PeftModel
from threading import Thread

# ===========================
# 1. 配置与环境
# ===========================
# 指定显卡
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0&quot;

# 路径配置 (请确认这些路径在你的服务器上是存在的)
BASE_MODEL_PATH = &quot;/home/mk/hanjia/jan_30/local_models/qwen/Qwen2___5-0___5B-Instruct&quot;
ADAPTER_PATH = &quot;./qwen_sft_finetuned&quot;

print(&quot;&gt;&gt;&gt; 正在初始化模型，请稍候...&quot;)

# ===========================
# 2. 加载模型
# ===========================
# 智能检测显卡是否支持 bfloat16
if torch.cuda.is_bf16_supported():
    print(&quot;✅ 显卡支持 BF16，启用 bf16 模式...&quot;)
    compute_dtype = torch.bfloat16
else:
    print(&quot;⚠️ 显卡不支持 BF16，使用 fp16 模式...&quot;)
    compute_dtype = torch.float16

tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)

# 加载底座
model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL_PATH,
    device_map=&quot;auto&quot;,
    torch_dtype=compute_dtype,
    attn_implementation=&quot;eager&quot; # 强制使用 eager 避免 flash_attn 报错
)

# 加载 LoRA 权重
print(f&quot;&gt;&gt;&gt; 正在挂载 LoRA 适配器: {ADAPTER_PATH}&quot;)
model = PeftModel.from_pretrained(model, ADAPTER_PATH)
model.eval() # 切换到评估模式

print(&quot;&gt;&gt;&gt; 模型加载完成！\n&quot;)
print(&quot;-&quot; * 50)
print(&quot;【交互模式使用指南】&quot;)
print(&quot;1. 直接输入内容开始对话&quot;)
print(&quot;2. 输入 'clear' 清空历史记录&quot;)
print(&quot;3. 输入 'exit' 退出程序&quot;)
print(&quot;-&quot; * 50)

# ===========================
# 3. 交互逻辑
# ===========================
def main():
    # 用于存储历史对话
    history = []

    while True:
        try:
            # 1. 获取用户输入
            query = input(&quot;\nUser: &quot;).strip()
            
            # 处理空输入
            if not query:
                continue
                
            # 处理退出命令
            if query.lower() in [&quot;exit&quot;, &quot;quit&quot;, &quot;退出&quot;]:
                print(&quot;👋 拜拜喵~&quot;)
                break
                
            # 处理清空命令
            if query.lower() == &quot;clear&quot;:
                history = []
                print(&quot;🧹 记忆已清除！&quot;)
                continue

            # 2. 将用户输入加入历史
            history.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: query})

            # 3. 构建 Prompt (应用 Chat 模板)
            input_text = tokenizer.apply_chat_template(
                history,
                tokenize=False,
                add_generation_prompt=True
            )
            
            # 4. 转为 Tensor 并移动到 GPU
            inputs = tokenizer([input_text], return_tensors=&quot;pt&quot;).to(model.device)

            # 5. 配置流式输出
            streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
            
            # 6. 生成参数配置 (修复了之前的字典语法错误)
            generation_kwargs = {
                &quot;input_ids&quot;: inputs.input_ids,
                &quot;attention_mask&quot;: inputs.attention_mask, # 加上这个更稳健
                &quot;streamer&quot;: streamer,
                &quot;max_new_tokens&quot;: 512,
                &quot;temperature&quot;: 0.7,
                &quot;top_p&quot;: 0.9,
                &quot;do_sample&quot;: True,
                &quot;repetition_penalty&quot;: 1.1
            }

            # 7. 多线程生成 (因为 streamer 是阻塞的)
            thread = Thread(target=model.generate, kwargs=generation_kwargs)
            thread.start()

            print(&quot;Assistant: &quot;, end=&quot;&quot;, flush=True)
            
            # 8. 实时打印输出并收集完整回复
            response_text = &quot;&quot;
            for new_text in streamer:
                print(new_text, end=&quot;&quot;, flush=True)
                response_text += new_text
            
            print() # 换行

            # 9. 将模型的回答加入历史
            history.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: response_text})

        except KeyboardInterrupt:
            print(&quot;\n👋 检测到中断，退出程序。&quot;)
            break
        except Exception as e:
            print(f&quot;\n❌ 发生错误: {e}&quot;)
            import traceback
            traceback.print_exc()

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>这是一个非常全面且高价值的总结请求。你刚刚不仅跑通了代码，还解决了从网络、环境到代码版本兼容性的一系列实际问题。</p>
<p>以下我将你在这次实战中涉及的<strong>所有重要知识点</strong>进行了系统化总结。这些内容足以支撑你在面试中回答关于 <strong>SFT（监督微调）</strong> 和 <strong>LLM 工程落地</strong> 的绝大多数核心问题。</p>
<hr>
<h3 id="第一部分核心理论架构-based-on-instructgpt">第一部分：核心理论架构 (Based on InstructGPT)</h3>
<p>这部分决定了你对“为什么这么做”的理解深度。</p>
<h4 id="1-对齐-alignment-的本质">1. 对齐 (Alignment) 的本质</h4>
<ul>
<li><strong>目标</strong>：预训练模型（Pre-trained Model）只会预测下一个词，它不在乎对错或好坏。我们的目标是让它变得 <strong>Helpful（有用）、Honest（诚实）、Harmless（无害）</strong>。</li>
<li><strong>手段</strong>：RLHF（Reinforcement Learning from Human Feedback）。</li>
</ul>
<h4 id="2-rlhf-三阶段流水线">2. RLHF 三阶段流水线</h4>
<p>面试必考题，必须能画出流程图。</p>
<ul>
<li><strong>Step 1: SFT (Supervised Fine-Tuning)</strong>
<ul>
<li><strong>本质</strong>：<strong>行为克隆 (Behavior Cloning)</strong>。</li>
<li><strong>做法</strong>：利用高质量的 <code>(Prompt, Answer)</code> 数据进行监督训练。</li>
<li><strong>作用</strong>：教会模型“怎么说话”，学会遵循对话格式。</li>
</ul>
</li>
<li><strong>Step 2: RM (Reward Model)</strong>
<ul>
<li><strong>本质</strong>：<strong>排序学习 (Ranking/Preference Learning)</strong>。</li>
<li><strong>做法</strong>：让模型对同一个问题的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 个回答进行排序（如 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>&gt;</mo><mi>B</mi><mo>&gt;</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A &gt; B &gt; C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>），构建成对数据 <code>(Chosen, Rejected)</code> 训练 RM。</li>
<li><strong>Loss</strong>：Pairwise Ranking Loss。</li>
</ul>
</li>
<li><strong>Step 3: PPO (Proximal Policy Optimization)</strong>
<ul>
<li><strong>本质</strong>：<strong>在约束下的自我进化</strong>。</li>
<li><strong>核心约束 (KL Penalty)</strong>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><msub><mi>R</mi><mrow><mi>R</mi><mi>M</mi></mrow></msub><mo>−</mo><mi>β</mi><mo>⋅</mo><mi>K</mi><mi>L</mi><mo>(</mo><msub><mi>π</mi><mrow><mi>R</mi><mi>L</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>π</mi><mrow><mi>S</mi><mi>F</mi><mi>T</mi></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">R_{total} = R_{RM} - \beta \cdot KL(\pi_{RL} || \pi_{SFT})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.00773em;">R</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">F</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li>
<li><strong>作用</strong>：防止模型为了骗取 RM 高分而胡言乱语（Reward Hacking），强迫模型不偏离 SFT 的语言分布。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="第二部分关键技术细节-sft-核心考点">第二部分：关键技术细节 (SFT 核心考点)</h3>
<p>这部分是你代码中 <code>SFTTrainer</code> 背后的逻辑。</p>
<h4 id="1-prompt-masking-指令掩码-最核心知识点">1. Prompt Masking (指令掩码) —— <strong>最核心知识点</strong></h4>
<ul>
<li><strong>面试问题</strong>：SFT 和预训练在 Loss 计算上有什么区别？</li>
<li><strong>回答</strong>：
<ul>
<li><strong>预训练</strong>：计算所有 Token 的 Loss。</li>
<li><strong>SFT</strong>：只计算 <strong>Assistant 回答部分</strong> 的 Loss。</li>
<li><strong>实现</strong>：将 User Prompt 部分的 <code>label</code> 设为 <strong>-100</strong>（PyTorch 中忽略 Loss 的索引）。这防止模型浪费梯度去“背诵问题”。</li>
</ul>
</li>
</ul>
<h4 id="2-chatml-数据格式">2. ChatML 数据格式</h4>
<ul>
<li><strong>问题</strong>：为什么不直接拼字符串，要用 <code>apply_chat_template</code>？</li>
<li><strong>回答</strong>：模型需要明确的特殊标记（Special Tokens）来区分谁在说话。
<ul>
<li>Qwen/ChatML 格式：<code>&lt;|im_start|&gt;user\n问题&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n回答&lt;|im_end|&gt;</code>。</li>
<li>如果格式不对，模型会学傻，分不清什么时候该停。</li>
</ul>
</li>
</ul>
<h4 id="3-过拟合悖论-overfitting-paradox">3. 过拟合悖论 (Overfitting Paradox)</h4>
<ul>
<li><strong>现象</strong>：SFT 训练中，验证集 Loss 很快就开始上升（过拟合），但人类评估的效果却还在变好。</li>
<li><strong>结论</strong>：在对齐任务中，Loss 不是唯一的衡量标准。OpenAI 建议不要看到 Loss 上升就立刻 Early Stop，要结合人工评估。</li>
</ul>
<hr>
<h3 id="第三部分工程实现方案-qlora">第三部分：工程实现方案 (QLoRA)</h3>
<p>这部分展示了你“如何在消费级显卡上训练大模型”的能力。</p>
<h4 id="1-qlora-原理">1. QLoRA 原理</h4>
<ul>
<li><strong>Quantization (量化)</strong>：使用 <code>BitsAndBytesConfig</code> 将底座模型以 <strong>4-bit NF4</strong> (Normal Float 4) 格式加载。
<ul>
<li><em>效果</em>：显存占用降为 FP16 的 1/4。</li>
</ul>
</li>
<li><strong>LoRA (Low-Rank Adaptation)</strong>：
<ul>
<li><strong>冻结</strong>：底座模型参数全部冻结（<code>requires_grad=False</code>）。</li>
<li><strong>旁路</strong>：在 Linear 层（如 Q, K, V Proj）旁挂载两个低秩矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>W</mi><mo mathvariant="normal">′</mo></msup><mo>=</mo><mi>W</mi><mo>+</mo><mi>B</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">W&#x27; = W + BA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span></span></span></span>)。</li>
<li><strong>训练</strong>：只更新 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>。参数量通常仅为原模型的 1% 甚至更少。</li>
</ul>
</li>
</ul>
<h4 id="2-显存优化技巧">2. 显存优化技巧</h4>
<ul>
<li><strong>梯度累积 (Gradient Accumulation)</strong>：
<ul>
<li><strong>场景</strong>：显存不够，Batch Size 只能开到 1。</li>
<li><strong>做法</strong>：<code>gradient_accumulation_steps=4</code>。模型前向传播 4 次才更新一次参数。</li>
<li><strong>效果</strong>：等效 Batch Size = 4，保证梯度下降的稳定性。</li>
</ul>
</li>
<li><strong>梯度检查点 (Gradient Checkpointing)</strong>：(代码中虽未显式开启，但这是省显存大招) 用“时间换空间”，不保存中间激活值，反向传播时重算。</li>
</ul>
<hr>
<h3 id="第四部分精度与硬件适配-你的-debug-经验">第四部分：精度与硬件适配 (你的 Debug 经验)</h3>
<p>这部分是你解决报错时积累的宝贵经验，体现了解决问题的能力。</p>
<h4 id="1-bf16-vs-fp16">1. BF16 vs FP16</h4>
<ul>
<li><strong>BF16 (BFloat16)</strong>：
<ul>
<li><strong>优点</strong>：动态范围与 FP32 相同，<strong>不需要 GradScaler</strong>，训练极其稳定，不易溢出。</li>
<li><strong>限制</strong>：只有 Ampere 架构（RTX 30系/A100）及以上支持。</li>
</ul>
</li>
<li><strong>FP16 (Float16)</strong>：
<ul>
<li><strong>优点</strong>：老显卡（T4/V100）都支持。</li>
<li><strong>缺点</strong>：动态范围小，<strong>必须使用 GradScaler</strong> 来防止梯度下溢（Underflow）。如果不小心混入了 BF16 权重，就会报错（你遇到的 <code>_amp_foreach_non_finite_check</code> 错误）。</li>
</ul>
</li>
</ul>
<h4 id="2-flash-attention">2. Flash Attention</h4>
<ul>
<li><strong>作用</strong>：极大地加速 Attention 计算并节省显存。</li>
<li><strong>坑</strong>：需要编译安装 <code>flash_attn</code> 库，对环境要求高。</li>
<li><strong>解决</strong>：在环境受限时，回退到 <code>attn_implementation=&quot;eager&quot;</code> (标准 PyTorch 实现) 是保证代码跑通的兜底方案。</li>
</ul>
<hr>
<h3 id="面试速记卡-cheat-sheet">面试速记卡 (Cheat Sheet)</h3>
<p>如果面试官问你：“请介绍一下你的 SFT 项目”，你可以按这个逻辑讲：</p>
<ol>
<li><strong>任务</strong>：基于 Qwen2-0.5B 进行指令微调，使其具备特定的角色扮演风格。</li>
<li><strong>方法</strong>：采用了 <strong>QLoRA</strong> 方案（4bit 量化 + LoRA），在单卡小显存环境下完成训练。</li>
<li><strong>数据</strong>：构建了 ChatML 格式数据，并使用了 <strong>Prompt Masking</strong> 技术，仅计算 Assistant 回答的 Loss。</li>
<li><strong>工程挑战</strong>：
<ul>
<li>解决了 <strong>TRL 库版本不兼容</strong> 导致的参数传递错误。</li>
<li>解决了 <strong>内网服务器无法下载模型</strong> 的问题（本地下载+上传）。</li>
<li>实现了 <strong>BF16/FP16 的自适应切换</strong>，解决了混合精度训练中的梯度缩放报错。</li>
<li>实现了 <strong>流式输出 (Streamer)</strong> 的多轮对话交互。</li>
</ul>
</li>
</ol>
<p>这一套下来，既有理论深度，又有工程落地能力，是非常完美的回答。祝你学习顺利！</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#%E8%AE%BA%E6%96%87%E6%A0%B8%E5%BF%83instructgpt-%E8%AF%A6%E8%A7%A3"><strong>论文核心：InstructGPT 详解</strong></a>
<ul>
<li><a href="#1-%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98%E5%AF%B9%E9%BD%90alignment"><strong>1. 核心问题：对齐（Alignment）</strong></a></li>
<li><a href="#2-%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BFrlhf-%E7%9A%84%E4%B8%89%E4%B8%AA%E9%98%B6%E6%AE%B5-%E5%9B%BE%E8%A7%A3-figure-2"><strong>2. 技术路线：RLHF 的三个阶段 (图解 Figure 2)</strong></a></li>
</ul>
</li>
<li><a href="#%E4%B8%80-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%A1%8C%E4%B8%BA%E5%85%8B%E9%9A%86-behavior-cloning">一、 核心概念：行为克隆 (Behavior Cloning)</a></li>
<li><a href="#%E4%BA%8C-%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8Bsft-%E7%9A%84%E7%87%83%E6%96%99">二、 数据工程：SFT 的燃料</a>
<ul>
<li><a href="#1-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90%E4%B8%8E%E6%9E%84%E6%88%90">1. 数据来源与构成</a></li>
<li><a href="#2-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%9A%E6%A0%B7%E6%80%A7-diversity">2. 数据的多样性 (Diversity)</a></li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E5%AE%9E%E6%88%98-jsonl">3. 数据格式实战 (JSONL)</a></li>
</ul>
</li>
<li><a href="#%E4%B8%89-%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82%E4%B8%8E-loss-%E8%AE%A1%E7%AE%97-%E6%8A%80%E6%9C%AF%E6%B7%B1%E6%8C%96">三、 训练细节与 Loss 计算 (技术深挖)</a>
<ul>
<li><a href="#1-loss-function-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">1. Loss Function (损失函数)</a></li>
<li><a href="#2-%E5%85%B3%E9%94%AE%E6%8A%80%E5%B7%A7prompt-masking-loss-masking">2. 关键技巧：Prompt Masking (Loss Masking)</a></li>
</ul>
</li>
<li><a href="#%E5%9B%9B-%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E5%8F%91%E7%8E%B0-insights">四、 论文中的关键发现 (Insights)</a>
<ul>
<li><a href="#1-%E8%BF%87%E6%8B%9F%E5%90%88%E6%82%96%E8%AE%BA-the-overfitting-paradox">1. “过拟合”悖论 (The Overfitting Paradox)</a></li>
<li><a href="#2-%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B-generalization">2. 泛化能力 (Generalization)</a></li>
</ul>
</li>
<li><a href="#%E4%BA%94-%E5%AE%9E%E6%88%98%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0-prompt-masking">五、 实战代码演示：如何实现 Prompt Masking</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#%E4%B8%80-%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E7%8B%AC%E7%AB%8B%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA-rm">一、 核心逻辑：为什么需要独立训练一个 RM？</a></li>
<li><a href="#%E4%BA%8C-%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E6%AF%94%E8%BE%83%E6%95%B0%E6%8D%AE%E9%9B%86">二、 数据工程：如何构建“比较数据集”</a>
<ul>
<li><a href="#1-%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B">1. 数据采集流程</a></li>
<li><a href="#2-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%8E%92%E5%BA%8Franking-vs-rating">2. 为什么是排序？(Ranking vs. Rating)</a></li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%9A%84%E9%AD%94%E6%B3%95">3. 数据增强的魔法</a></li>
</ul>
</li>
<li><a href="#%E4%B8%89-%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E5%A6%82%E4%BD%95%E6%8A%8A-llm-%E5%8F%98%E6%88%90%E6%89%93%E5%88%86%E5%99%A8">三、 模型架构：如何把 LLM 变成打分器</a></li>
<li><a href="#%E5%9B%9B-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-loss-function-%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90">四、 损失函数 (Loss Function) 深度解析</a>
<ul>
<li><a href="#1-%E6%A0%B8%E5%BF%83%E9%A1%B9r_thetax-y_w-r_thetax-y_l">1. 核心项：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo>)</mo><mo>−</mo><msub><mi>r</mi><mi>θ</mi></msub><mo>(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">r_\theta(x, y_w) - r_\theta(x, y_l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></a></li>
<li><a href="#2-sigmoid-%E5%87%BD%E6%95%B0-sigma">2. Sigmoid 函数 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>)</a></li>
<li><a href="#3-log-%E5%AF%B9%E6%95%B0-log">3. Log 对数 (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span></span></span></span>)</a></li>
</ul>
</li>
<li><a href="#%E4%BA%94-%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%B7%A5%E7%A8%8B%E9%BB%91%E9%AD%94%E6%B3%95batching-%E7%AD%96%E7%95%A5">五、 论文中的工程黑魔法：Batching 策略</a></li>
<li><a href="#%E5%85%AD-%E5%AE%9E%E6%88%98%E4%BB%A3%E7%A0%81%E9%80%BB%E8%BE%91-pytorch">六、 实战代码逻辑 (PyTorch)</a></li>
<li><a href="#%E6%80%BB%E7%BB%93-2">总结</a></li>
<li><a href="#%E4%B8%80-%E5%AE%8F%E8%A7%82%E6%9E%B6%E6%9E%84rlhf-%E4%B8%AD%E7%9A%84%E5%9B%9B%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F">一、 宏观架构：RLHF 中的“四模型”系统</a></li>
<li><a href="#%E4%BA%8C-%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6kl-%E6%83%A9%E7%BD%9A-the-kl-penalty">二、 核心机制：KL 惩罚 (The KL Penalty)</a>
<ul>
<li><a href="#1-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%9C%89-reward-hacking">1. 为什么会有 Reward Hacking？</a></li>
<li><a href="#2-kl-%E6%95%A3%E5%BA%A6-kullback-leibler-divergence">2. KL 散度 (Kullback-Leibler Divergence)</a></li>
</ul>
</li>
<li><a href="#1-%E7%9B%B4%E8%A7%89%E7%90%86%E8%A7%A3%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%8A%A0%E8%BF%99%E4%B8%AA%E6%83%A9%E7%BD%9A">1. 直觉理解：为什么要加这个惩罚？</a></li>
<li><a href="#2-%E6%95%B0%E5%AD%A6%E6%8B%86%E8%A7%A3%E5%85%AC%E5%BC%8F%E6%98%AF%E5%A6%82%E4%BD%95%E6%83%A9%E7%BD%9A%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD%E7%9A%84">2. 数学拆解：公式是如何惩罚“胡言乱语”的？</a>
<ul>
<li><a href="#%E5%9C%BA%E6%99%AF-a%E6%AD%A3%E5%B8%B8%E7%9A%84%E5%BE%AE%E8%B0%83-good-case">场景 A：正常的微调 (Good Case)</a></li>
<li><a href="#%E5%9C%BA%E6%99%AF-b%E5%A5%96%E5%8A%B1%E9%BB%91%E5%AE%A2-reward-hacking-bad-case">场景 B：奖励黑客 (Reward Hacking / Bad Case)</a></li>
</ul>
</li>
<li><a href="#3-%E5%B7%A5%E7%A8%8B%E5%AE%9E%E7%8E%B0reference-model">3. 工程实现：Reference Model</a></li>
<li><a href="#4-%E8%BF%99%E9%87%8C%E7%9A%84-beta-beta-%E6%98%AF%E4%BB%80%E4%B9%88">4. 这里的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> (Beta) 是什么？</a></li>
<li><a href="#5-%E6%80%BB%E7%BB%93">5. 总结</a></li>
<li><a href="#%E4%B8%89-%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8Bppo-%E7%9A%84%E6%AF%8F%E4%B8%80%E6%AD%A5">三、 算法流程：PPO 的每一步</a></li>
<li><a href="#%E5%9B%9B-ppo-ptx-%E8%A7%A3%E5%86%B3%E5%AF%B9%E9%BD%90%E7%A8%8E-alignment-tax">四、 PPO-ptx: 解决“对齐税” (Alignment Tax)</a>
<ul>
<li><a href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%AF%B9%E9%BD%90%E7%A8%8E">1. 什么是对齐税？</a></li>
<li><a href="#2-ppo-ptx-pretraining-mix-%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">2. PPO-ptx (Pretraining Mix) 的解决方案</a></li>
</ul>
</li>
<li><a href="#%E4%BA%94-%E6%80%BB%E7%BB%93%E4%B8%8E%E5%A4%8D%E7%9B%98">五、 总结与复盘</a>
<ul>
<li><a href="#3-%E6%A0%B8%E5%BF%83%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><strong>3. 核心实验结果</strong></a></li>
<li><a href="#4-%E6%95%B0%E6%8D%AE%E7%BB%86%E8%8A%82-data-details"><strong>4. 数据细节 (Data Details)</strong></a></li>
</ul>
</li>
<li><a href="#1-%E9%80%BB%E8%BE%91%E5%B1%82%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-chosen-vs-rejected">1. 逻辑层：为什么是 &quot;Chosen vs Rejected&quot;？</a>
<ul>
<li><a href="#%E8%BF%99%E9%87%8C%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6%E5%8E%9F%E7%90%86">这里的心理学原理：</a></li>
</ul>
</li>
<li><a href="#2-%E6%96%87%E4%BB%B6%E5%B1%82json-%E6%95%B0%E6%8D%AE%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7">2. 文件层：JSON 数据长什么样？</a>
<ul>
<li><a href="#%E6%A0%87%E5%87%86%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B">标准数据结构示例</a></li>
<li><a href="#%E8%BF%9B%E9%98%B6%E4%BB%8E%E6%8E%92%E5%90%8D%E5%88%B0%E6%88%90%E5%AF%B9%E6%95%B0%E6%8D%AE-data-expansion">进阶：从“排名”到“成对数据” (Data Expansion)</a></li>
</ul>
</li>
<li><a href="#3-%E4%BB%A3%E7%A0%81%E5%B1%82%E6%A8%A1%E5%9E%8B%E7%9C%9F%E6%AD%A3%E7%9C%8B%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88">3. 代码层：模型真正看到的是什么？</a>
<ul>
<li><a href="#1-tokenization-%E5%88%86%E8%AF%8D">(1) Tokenization (分词)</a></li>
<li><a href="#2-batch-construction-%E7%BB%84%E6%88%90%E6%89%B9%E6%AC%A1">(2) Batch Construction (组成批次)</a></li>
<li><a href="#3-forward-pass-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD">(3) Forward Pass (前向传播)</a></li>
</ul>
</li>
<li><a href="#4-%E5%85%B3%E9%94%AEreward-model-%E7%9A%84%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F">4. 关键：Reward Model 的输出格式</a></li>
<li><a href="#5-%E6%80%BB%E7%BB%93-2">5. 总结</a></li>
<li><a href="#1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">1. 环境准备</a></li>
<li><a href="#2-%E5%AE%8C%E6%95%B4%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81-train_sftpy">2. 完整训练代码 (<code>train_sft.py</code>)</a></li>
<li><a href="#3-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C">3. 如何验证训练结果？</a></li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%A0%B8%E5%BF%83%E7%90%86%E8%AE%BA%E6%9E%B6%E6%9E%84-based-on-instructgpt">第一部分：核心理论架构 (Based on InstructGPT)</a>
<ul>
<li><a href="#1-%E5%AF%B9%E9%BD%90-alignment-%E7%9A%84%E6%9C%AC%E8%B4%A8">1. 对齐 (Alignment) 的本质</a></li>
<li><a href="#2-rlhf-%E4%B8%89%E9%98%B6%E6%AE%B5%E6%B5%81%E6%B0%B4%E7%BA%BF">2. RLHF 三阶段流水线</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82-sft-%E6%A0%B8%E5%BF%83%E8%80%83%E7%82%B9">第二部分：关键技术细节 (SFT 核心考点)</a>
<ul>
<li><a href="#1-prompt-masking-%E6%8C%87%E4%BB%A4%E6%8E%A9%E7%A0%81-%E6%9C%80%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9">1. Prompt Masking (指令掩码) —— <strong>最核心知识点</strong></a></li>
<li><a href="#2-chatml-%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F">2. ChatML 数据格式</a></li>
<li><a href="#3-%E8%BF%87%E6%8B%9F%E5%90%88%E6%82%96%E8%AE%BA-overfitting-paradox">3. 过拟合悖论 (Overfitting Paradox)</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88-qlora">第三部分：工程实现方案 (QLoRA)</a>
<ul>
<li><a href="#1-qlora-%E5%8E%9F%E7%90%86">1. QLoRA 原理</a></li>
<li><a href="#2-%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7">2. 显存优化技巧</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E7%B2%BE%E5%BA%A6%E4%B8%8E%E7%A1%AC%E4%BB%B6%E9%80%82%E9%85%8D-%E4%BD%A0%E7%9A%84-debug-%E7%BB%8F%E9%AA%8C">第四部分：精度与硬件适配 (你的 Debug 经验)</a>
<ul>
<li><a href="#1-bf16-vs-fp16">1. BF16 vs FP16</a></li>
<li><a href="#2-flash-attention">2. Flash Attention</a></li>
</ul>
</li>
<li><a href="#%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0%E5%8D%A1-cheat-sheet">面试速记卡 (Cheat Sheet)</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://Alive-mk.github.io/post/ppo-suan-fa-xue-xi-yu-shi-zhan-shou-ce/">
              <h3 class="post-title">
                PPO 算法学习与实战手册
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://Alive-mk.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
